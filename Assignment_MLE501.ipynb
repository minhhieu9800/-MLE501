{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyO7K73BWJeQa0FEkV1KZjcT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/minhhieu9800/MLE501/blob/main/Assignment_MLE501.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Giới thiệu\n",
        "\n",
        "Họ tên: Nguyễn Minh Hiếu </br>\n",
        "Lớp: MSE#11HCM </br>\n",
        "Mã học viên: 22MSE23062 </br>\n",
        "Email: hieu22mse23062@fsb.edu.vn"
      ],
      "metadata": {
        "id": "AaecXjCquLAG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Assignment"
      ],
      "metadata": {
        "id": "hYaKemdZvyGv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from tabulate import tabulate\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.models import load_model\n",
        "from keras.optimizers import Adam, RMSprop\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "F15QZDthv7nc"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load dữ liệu"
      ],
      "metadata": {
        "id": "u0RGH5Du5V9h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "url = 'https://minhhieu9800.github.io/MLE501/diabetes.csv'\n",
        "df = pd.read_csv(url)"
      ],
      "metadata": {
        "id": "EbTZStr3yU1C"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = df.drop(['Outcome'], axis=1)\n",
        "y = df['Outcome']\n",
        "\n",
        "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.2)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.2)"
      ],
      "metadata": {
        "id": "eTXALQYuyb26"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Xây dựng model"
      ],
      "metadata": {
        "id": "70D9DjkU5TJj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(8, input_dim=8, activation='relu'))\n",
        "model.add(Dense(8, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.summary()\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.fit(X_train, y_train, epochs=100, batch_size=8, validation_data=(X_val, y_val))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "maH048DE55yx",
        "outputId": "fa33975a-aeb3-441f-c5cb-ff3a458dbf1d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 8)                 72        \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 8)                 72        \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1)                 9         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 153\n",
            "Trainable params: 153\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "62/62 [==============================] - 2s 16ms/step - loss: 2.6303 - accuracy: 0.5580 - val_loss: 1.3686 - val_accuracy: 0.6098\n",
            "Epoch 2/100\n",
            "62/62 [==============================] - 1s 9ms/step - loss: 1.2791 - accuracy: 0.5886 - val_loss: 1.2062 - val_accuracy: 0.5203\n",
            "Epoch 3/100\n",
            "62/62 [==============================] - 1s 10ms/step - loss: 1.1378 - accuracy: 0.5845 - val_loss: 1.1413 - val_accuracy: 0.5447\n",
            "Epoch 4/100\n",
            "62/62 [==============================] - 1s 17ms/step - loss: 1.0480 - accuracy: 0.6008 - val_loss: 1.0207 - val_accuracy: 0.5772\n",
            "Epoch 5/100\n",
            "62/62 [==============================] - 1s 10ms/step - loss: 0.9842 - accuracy: 0.6212 - val_loss: 0.9706 - val_accuracy: 0.5691\n",
            "Epoch 6/100\n",
            "62/62 [==============================] - 1s 13ms/step - loss: 0.9393 - accuracy: 0.6273 - val_loss: 0.9435 - val_accuracy: 0.6016\n",
            "Epoch 7/100\n",
            "62/62 [==============================] - 1s 11ms/step - loss: 0.9063 - accuracy: 0.6151 - val_loss: 0.8883 - val_accuracy: 0.6423\n",
            "Epoch 8/100\n",
            "62/62 [==============================] - 1s 13ms/step - loss: 0.8750 - accuracy: 0.6253 - val_loss: 0.8152 - val_accuracy: 0.6585\n",
            "Epoch 9/100\n",
            "62/62 [==============================] - 1s 12ms/step - loss: 0.8490 - accuracy: 0.5988 - val_loss: 0.8189 - val_accuracy: 0.6341\n",
            "Epoch 10/100\n",
            "62/62 [==============================] - 1s 9ms/step - loss: 0.8210 - accuracy: 0.6212 - val_loss: 0.7521 - val_accuracy: 0.6341\n",
            "Epoch 11/100\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.7965 - accuracy: 0.6314 - val_loss: 0.6701 - val_accuracy: 0.6911\n",
            "Epoch 12/100\n",
            "62/62 [==============================] - 1s 8ms/step - loss: 0.7341 - accuracy: 0.6436 - val_loss: 0.6452 - val_accuracy: 0.6992\n",
            "Epoch 13/100\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.7064 - accuracy: 0.6578 - val_loss: 0.6286 - val_accuracy: 0.7073\n",
            "Epoch 14/100\n",
            "62/62 [==============================] - 0s 8ms/step - loss: 0.7002 - accuracy: 0.6640 - val_loss: 0.6312 - val_accuracy: 0.7073\n",
            "Epoch 15/100\n",
            "62/62 [==============================] - 0s 8ms/step - loss: 0.6883 - accuracy: 0.6680 - val_loss: 0.6120 - val_accuracy: 0.7154\n",
            "Epoch 16/100\n",
            "62/62 [==============================] - 1s 11ms/step - loss: 0.6762 - accuracy: 0.6599 - val_loss: 0.5947 - val_accuracy: 0.6748\n",
            "Epoch 17/100\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.6593 - accuracy: 0.6884 - val_loss: 0.6064 - val_accuracy: 0.7154\n",
            "Epoch 18/100\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.6590 - accuracy: 0.6721 - val_loss: 0.5874 - val_accuracy: 0.7154\n",
            "Epoch 19/100\n",
            "62/62 [==============================] - 1s 8ms/step - loss: 0.6494 - accuracy: 0.6802 - val_loss: 0.5781 - val_accuracy: 0.7317\n",
            "Epoch 20/100\n",
            "62/62 [==============================] - 1s 9ms/step - loss: 0.6442 - accuracy: 0.6823 - val_loss: 0.6138 - val_accuracy: 0.7480\n",
            "Epoch 21/100\n",
            "62/62 [==============================] - 1s 8ms/step - loss: 0.6481 - accuracy: 0.6843 - val_loss: 0.5766 - val_accuracy: 0.6992\n",
            "Epoch 22/100\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.6442 - accuracy: 0.6721 - val_loss: 0.5818 - val_accuracy: 0.7317\n",
            "Epoch 23/100\n",
            "62/62 [==============================] - 1s 8ms/step - loss: 0.6368 - accuracy: 0.6823 - val_loss: 0.5695 - val_accuracy: 0.7398\n",
            "Epoch 24/100\n",
            "62/62 [==============================] - 0s 8ms/step - loss: 0.6266 - accuracy: 0.6843 - val_loss: 0.5655 - val_accuracy: 0.7398\n",
            "Epoch 25/100\n",
            "62/62 [==============================] - 1s 10ms/step - loss: 0.6339 - accuracy: 0.6884 - val_loss: 0.5710 - val_accuracy: 0.7398\n",
            "Epoch 26/100\n",
            "62/62 [==============================] - 1s 8ms/step - loss: 0.6144 - accuracy: 0.6904 - val_loss: 0.5626 - val_accuracy: 0.7398\n",
            "Epoch 27/100\n",
            "62/62 [==============================] - 1s 8ms/step - loss: 0.6184 - accuracy: 0.6904 - val_loss: 0.5646 - val_accuracy: 0.7480\n",
            "Epoch 28/100\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.6130 - accuracy: 0.6925 - val_loss: 0.5556 - val_accuracy: 0.7398\n",
            "Epoch 29/100\n",
            "62/62 [==============================] - 1s 9ms/step - loss: 0.6099 - accuracy: 0.6945 - val_loss: 0.5500 - val_accuracy: 0.7154\n",
            "Epoch 30/100\n",
            "62/62 [==============================] - 1s 10ms/step - loss: 0.6083 - accuracy: 0.6986 - val_loss: 0.5866 - val_accuracy: 0.7317\n",
            "Epoch 31/100\n",
            "62/62 [==============================] - 1s 18ms/step - loss: 0.6075 - accuracy: 0.6884 - val_loss: 0.5633 - val_accuracy: 0.6829\n",
            "Epoch 32/100\n",
            "62/62 [==============================] - 1s 13ms/step - loss: 0.6092 - accuracy: 0.6843 - val_loss: 0.5411 - val_accuracy: 0.7480\n",
            "Epoch 33/100\n",
            "62/62 [==============================] - 1s 14ms/step - loss: 0.6037 - accuracy: 0.6884 - val_loss: 0.5606 - val_accuracy: 0.7073\n",
            "Epoch 34/100\n",
            "62/62 [==============================] - 1s 12ms/step - loss: 0.6050 - accuracy: 0.6843 - val_loss: 0.5428 - val_accuracy: 0.7154\n",
            "Epoch 35/100\n",
            "62/62 [==============================] - 1s 11ms/step - loss: 0.6015 - accuracy: 0.6925 - val_loss: 0.5584 - val_accuracy: 0.7480\n",
            "Epoch 36/100\n",
            "62/62 [==============================] - 1s 12ms/step - loss: 0.5982 - accuracy: 0.7026 - val_loss: 0.5488 - val_accuracy: 0.6911\n",
            "Epoch 37/100\n",
            "62/62 [==============================] - 1s 8ms/step - loss: 0.5979 - accuracy: 0.6884 - val_loss: 0.5410 - val_accuracy: 0.7480\n",
            "Epoch 38/100\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.5892 - accuracy: 0.7108 - val_loss: 0.5507 - val_accuracy: 0.6992\n",
            "Epoch 39/100\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.5878 - accuracy: 0.7108 - val_loss: 0.5684 - val_accuracy: 0.7317\n",
            "Epoch 40/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.5913 - accuracy: 0.7088 - val_loss: 0.5563 - val_accuracy: 0.6829\n",
            "Epoch 41/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.5974 - accuracy: 0.7128 - val_loss: 0.5440 - val_accuracy: 0.7317\n",
            "Epoch 42/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.5945 - accuracy: 0.7067 - val_loss: 0.5520 - val_accuracy: 0.7561\n",
            "Epoch 43/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.5899 - accuracy: 0.7128 - val_loss: 0.5629 - val_accuracy: 0.7561\n",
            "Epoch 44/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.5846 - accuracy: 0.7047 - val_loss: 0.5611 - val_accuracy: 0.6992\n",
            "Epoch 45/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.5937 - accuracy: 0.6945 - val_loss: 0.5544 - val_accuracy: 0.7642\n",
            "Epoch 46/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.5834 - accuracy: 0.6864 - val_loss: 0.5525 - val_accuracy: 0.7073\n",
            "Epoch 47/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.5834 - accuracy: 0.7026 - val_loss: 0.5503 - val_accuracy: 0.7398\n",
            "Epoch 48/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.5873 - accuracy: 0.6965 - val_loss: 0.5469 - val_accuracy: 0.7561\n",
            "Epoch 49/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.5902 - accuracy: 0.6986 - val_loss: 0.5410 - val_accuracy: 0.7236\n",
            "Epoch 50/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.5894 - accuracy: 0.7088 - val_loss: 0.5936 - val_accuracy: 0.7398\n",
            "Epoch 51/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.5838 - accuracy: 0.7128 - val_loss: 0.5456 - val_accuracy: 0.7317\n",
            "Epoch 52/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.5765 - accuracy: 0.7128 - val_loss: 0.5567 - val_accuracy: 0.7561\n",
            "Epoch 53/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.5764 - accuracy: 0.7067 - val_loss: 0.5532 - val_accuracy: 0.7236\n",
            "Epoch 54/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.5779 - accuracy: 0.7128 - val_loss: 0.5468 - val_accuracy: 0.7561\n",
            "Epoch 55/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.5694 - accuracy: 0.7067 - val_loss: 0.5408 - val_accuracy: 0.7317\n",
            "Epoch 56/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.5867 - accuracy: 0.7169 - val_loss: 0.5406 - val_accuracy: 0.7317\n",
            "Epoch 57/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.5730 - accuracy: 0.7026 - val_loss: 0.5525 - val_accuracy: 0.7642\n",
            "Epoch 58/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.5750 - accuracy: 0.7006 - val_loss: 0.5343 - val_accuracy: 0.7236\n",
            "Epoch 59/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.5679 - accuracy: 0.7149 - val_loss: 0.5368 - val_accuracy: 0.7398\n",
            "Epoch 60/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.5737 - accuracy: 0.7230 - val_loss: 0.5330 - val_accuracy: 0.7561\n",
            "Epoch 61/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.5758 - accuracy: 0.7067 - val_loss: 0.5372 - val_accuracy: 0.7805\n",
            "Epoch 62/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.6056 - accuracy: 0.6782 - val_loss: 0.5389 - val_accuracy: 0.7154\n",
            "Epoch 63/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.5686 - accuracy: 0.7189 - val_loss: 0.5478 - val_accuracy: 0.7480\n",
            "Epoch 64/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.5733 - accuracy: 0.7128 - val_loss: 0.5447 - val_accuracy: 0.7236\n",
            "Epoch 65/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.5863 - accuracy: 0.7067 - val_loss: 0.5365 - val_accuracy: 0.7236\n",
            "Epoch 66/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.5679 - accuracy: 0.7047 - val_loss: 0.5354 - val_accuracy: 0.7561\n",
            "Epoch 67/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.5634 - accuracy: 0.7373 - val_loss: 0.5369 - val_accuracy: 0.7236\n",
            "Epoch 68/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.5573 - accuracy: 0.7251 - val_loss: 0.5535 - val_accuracy: 0.7398\n",
            "Epoch 69/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.5701 - accuracy: 0.7149 - val_loss: 0.5352 - val_accuracy: 0.7398\n",
            "Epoch 70/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.5655 - accuracy: 0.6986 - val_loss: 0.5498 - val_accuracy: 0.7398\n",
            "Epoch 71/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.5672 - accuracy: 0.7088 - val_loss: 0.5419 - val_accuracy: 0.7642\n",
            "Epoch 72/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.5702 - accuracy: 0.7149 - val_loss: 0.5355 - val_accuracy: 0.7561\n",
            "Epoch 73/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.5654 - accuracy: 0.7067 - val_loss: 0.5288 - val_accuracy: 0.7317\n",
            "Epoch 74/100\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.5622 - accuracy: 0.7352 - val_loss: 0.5351 - val_accuracy: 0.7236\n",
            "Epoch 75/100\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.5633 - accuracy: 0.7251 - val_loss: 0.5439 - val_accuracy: 0.7561\n",
            "Epoch 76/100\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.5716 - accuracy: 0.7169 - val_loss: 0.5234 - val_accuracy: 0.7236\n",
            "Epoch 77/100\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.5511 - accuracy: 0.7210 - val_loss: 0.5311 - val_accuracy: 0.7724\n",
            "Epoch 78/100\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.5635 - accuracy: 0.7128 - val_loss: 0.5404 - val_accuracy: 0.7480\n",
            "Epoch 79/100\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.5655 - accuracy: 0.7108 - val_loss: 0.5244 - val_accuracy: 0.7236\n",
            "Epoch 80/100\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.5633 - accuracy: 0.7108 - val_loss: 0.5400 - val_accuracy: 0.7724\n",
            "Epoch 81/100\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.5513 - accuracy: 0.7251 - val_loss: 0.5247 - val_accuracy: 0.7642\n",
            "Epoch 82/100\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.5549 - accuracy: 0.7169 - val_loss: 0.5289 - val_accuracy: 0.7236\n",
            "Epoch 83/100\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.5543 - accuracy: 0.7230 - val_loss: 0.5193 - val_accuracy: 0.7724\n",
            "Epoch 84/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.5570 - accuracy: 0.7108 - val_loss: 0.5278 - val_accuracy: 0.7805\n",
            "Epoch 85/100\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.5543 - accuracy: 0.7169 - val_loss: 0.5318 - val_accuracy: 0.7236\n",
            "Epoch 86/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.5505 - accuracy: 0.7332 - val_loss: 0.5509 - val_accuracy: 0.7398\n",
            "Epoch 87/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.5512 - accuracy: 0.7332 - val_loss: 0.5241 - val_accuracy: 0.7805\n",
            "Epoch 88/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.5509 - accuracy: 0.7251 - val_loss: 0.5219 - val_accuracy: 0.7724\n",
            "Epoch 89/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.5485 - accuracy: 0.7169 - val_loss: 0.5227 - val_accuracy: 0.7561\n",
            "Epoch 90/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.5501 - accuracy: 0.7230 - val_loss: 0.5397 - val_accuracy: 0.7642\n",
            "Epoch 91/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.5555 - accuracy: 0.7189 - val_loss: 0.5222 - val_accuracy: 0.7886\n",
            "Epoch 92/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.5484 - accuracy: 0.7332 - val_loss: 0.5324 - val_accuracy: 0.7317\n",
            "Epoch 93/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.5495 - accuracy: 0.7515 - val_loss: 0.5551 - val_accuracy: 0.6829\n",
            "Epoch 94/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.5545 - accuracy: 0.7067 - val_loss: 0.5271 - val_accuracy: 0.7724\n",
            "Epoch 95/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.5368 - accuracy: 0.7413 - val_loss: 0.5546 - val_accuracy: 0.7480\n",
            "Epoch 96/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.5585 - accuracy: 0.7108 - val_loss: 0.5293 - val_accuracy: 0.7398\n",
            "Epoch 97/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.5532 - accuracy: 0.7230 - val_loss: 0.5507 - val_accuracy: 0.6992\n",
            "Epoch 98/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.5601 - accuracy: 0.7210 - val_loss: 0.5277 - val_accuracy: 0.7724\n",
            "Epoch 99/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.5404 - accuracy: 0.7352 - val_loss: 0.5280 - val_accuracy: 0.7886\n",
            "Epoch 100/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.5374 - accuracy: 0.7393 - val_loss: 0.5320 - val_accuracy: 0.7724\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7ff6852f8370>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"model.h5\")"
      ],
      "metadata": {
        "id": "6hEeFRlL6o44"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = load_model(\"model.h5\")"
      ],
      "metadata": {
        "id": "M0Q_XLUU-o3A"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(\"Loss: \", loss)\n",
        "print(\"Accuracy: \", accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uSMZ-Tb__Xtf",
        "outputId": "23652909-981e-42c9-d7b7-036e9e3daf7d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6241 - accuracy: 0.6753\n",
            "Loss:  0.6241394877433777\n",
            "Accuracy:  0.6753246784210205\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sử dụng Hyperparameter Tuning (Keras Tuner)"
      ],
      "metadata": {
        "id": "grEAzn7nZVp_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install keras-tuner\n",
        "import keras_tuner as kt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "npqDTQMsUpLh",
        "outputId": "9f78e211-aa17-4cce-a7f4-f5cf669bf3ba"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting keras-tuner\n",
            "  Downloading keras_tuner-1.3.0-py3-none-any.whl (167 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.3/167.3 KB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting kt-legacy\n",
            "  Downloading kt_legacy-1.0.4-py3-none-any.whl (9.6 kB)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.8/dist-packages (from keras-tuner) (7.9.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from keras-tuner) (2.25.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from keras-tuner) (23.0)\n",
            "Requirement already satisfied: tensorflow>=2.0 in /usr/local/lib/python3.8/dist-packages (from keras-tuner) (2.11.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0->keras-tuner) (1.6.3)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0->keras-tuner) (1.15.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0->keras-tuner) (2.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0->keras-tuner) (3.1.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0->keras-tuner) (1.15.0)\n",
            "Requirement already satisfied: keras<2.12,>=2.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0->keras-tuner) (2.11.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0->keras-tuner) (15.0.6.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0->keras-tuner) (0.31.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0->keras-tuner) (1.51.3)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0->keras-tuner) (3.19.6)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0->keras-tuner) (1.24.2)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0->keras-tuner) (23.1.21)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0->keras-tuner) (0.2.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.12,>=2.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0->keras-tuner) (2.11.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0->keras-tuner) (57.4.0)\n",
            "Requirement already satisfied: tensorboard<2.12,>=2.11 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0->keras-tuner) (2.11.2)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0->keras-tuner) (0.4.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0->keras-tuner) (1.4.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0->keras-tuner) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0->keras-tuner) (4.5.0)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.8/dist-packages (from ipython->keras-tuner) (2.6.1)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.8/dist-packages (from ipython->keras-tuner) (4.8.0)\n",
            "Collecting jedi>=0.10\n",
            "  Downloading jedi-0.18.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m30.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: decorator in /usr/local/lib/python3.8/dist-packages (from ipython->keras-tuner) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.8/dist-packages (from ipython->keras-tuner) (0.7.5)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.8/dist-packages (from ipython->keras-tuner) (0.2.0)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.8/dist-packages (from ipython->keras-tuner) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit<2.1.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from ipython->keras-tuner) (2.0.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->keras-tuner) (1.26.14)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->keras-tuner) (4.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->keras-tuner) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->keras-tuner) (2022.12.7)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.8/dist-packages (from astunparse>=1.6.0->tensorflow>=2.0->keras-tuner) (0.38.4)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.8/dist-packages (from jedi>=0.10->ipython->keras-tuner) (0.8.3)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.8/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython->keras-tuner) (0.2.6)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow>=2.0->keras-tuner) (2.16.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow>=2.0->keras-tuner) (0.4.6)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow>=2.0->keras-tuner) (3.4.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow>=2.0->keras-tuner) (0.6.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow>=2.0->keras-tuner) (2.2.3)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow>=2.0->keras-tuner) (1.8.1)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.8/dist-packages (from pexpect->ipython->keras-tuner) (0.7.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow>=2.0->keras-tuner) (4.9)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow>=2.0->keras-tuner) (5.3.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow>=2.0->keras-tuner) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow>=2.0->keras-tuner) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.8/dist-packages (from markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow>=2.0->keras-tuner) (6.0.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.8/dist-packages (from werkzeug>=1.0.1->tensorboard<2.12,>=2.11->tensorflow>=2.0->keras-tuner) (2.1.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow>=2.0->keras-tuner) (3.15.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow>=2.0->keras-tuner) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow>=2.0->keras-tuner) (3.2.2)\n",
            "Installing collected packages: kt-legacy, jedi, keras-tuner\n",
            "Successfully installed jedi-0.18.2 keras-tuner-1.3.0 kt-legacy-1.0.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tạm hàm build Hyper model\n",
        "def build_model(hp): \n",
        "  model = keras.Sequential()\n",
        "\n",
        "  X = hp.Int('units_input', min_value=8, max_value=64, step=8)\n",
        "  model.add(Dense(units=X, input_dim=8, activation='relu'))\n",
        "\n",
        "  for i in range(hp.Int('num_layers', 1, 4)):\n",
        "    Y = hp.Int('units_' + str(i), min_value=8, max_value=64, step=8)\n",
        "    model.add(Dense(units=Y, activation='relu'))\n",
        "\n",
        "  model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "  lr = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
        "  model.compile(\n",
        "        optimizer=Adam(learning_rate=lr),\n",
        "        loss='binary_crossentropy',\n",
        "        metrics=['accuracy'])\n",
        "  \n",
        "  return model"
      ],
      "metadata": {
        "id": "TZZiAkkUOb81"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Khởi tạo Tuner\n",
        "tuner = kt.Hyperband (build_model, objective=\"val_accuracy\", directory=\"tuner_dir_1\", project_name=\"MLE501_Tuner_1\")"
      ],
      "metadata": {
        "id": "_jzNzE7NT-5O"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tuner.search(X_train, y_train, epochs=10, validation_data=(X_val, y_val))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O_njRkaEWHo6",
        "outputId": "ca3c6b0e-2161-455f-c18a-217828de0780"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 254 Complete [00h 00m 15s]\n",
            "val_accuracy: 0.642276406288147\n",
            "\n",
            "Best val_accuracy So Far: 0.8455284833908081\n",
            "Total elapsed time: 00h 15m 22s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# lấy best model\n",
        "best_model = tuner.get_best_models(num_models=1)[0]\n",
        "\n",
        "best_model.summary()\n",
        "\n",
        "best_model.fit(X_train, y_train, epochs=100, batch_size=8, validation_data=(X_val, y_val))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yYYXWVBTZSA9",
        "outputId": "296e111a-cacf-4445-ae0b-15d23a75c561"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 56)                504       \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 40)                2280      \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 40)                1640      \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 64)                2624      \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 7,113\n",
            "Trainable params: 7,113\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "62/62 [==============================] - 3s 20ms/step - loss: 0.5785 - accuracy: 0.6884 - val_loss: 0.4794 - val_accuracy: 0.7642\n",
            "Epoch 2/100\n",
            "62/62 [==============================] - 0s 8ms/step - loss: 0.5751 - accuracy: 0.7128 - val_loss: 0.6057 - val_accuracy: 0.6423\n",
            "Epoch 3/100\n",
            "62/62 [==============================] - 1s 8ms/step - loss: 0.5540 - accuracy: 0.7108 - val_loss: 0.4880 - val_accuracy: 0.7561\n",
            "Epoch 4/100\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.5341 - accuracy: 0.7271 - val_loss: 0.4507 - val_accuracy: 0.8130\n",
            "Epoch 5/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.5534 - accuracy: 0.7434 - val_loss: 0.5022 - val_accuracy: 0.7561\n",
            "Epoch 6/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.5374 - accuracy: 0.7189 - val_loss: 0.4958 - val_accuracy: 0.7724\n",
            "Epoch 7/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.5251 - accuracy: 0.7454 - val_loss: 0.4298 - val_accuracy: 0.8537\n",
            "Epoch 8/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.5290 - accuracy: 0.7413 - val_loss: 0.4442 - val_accuracy: 0.8293\n",
            "Epoch 9/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.5606 - accuracy: 0.7251 - val_loss: 0.5560 - val_accuracy: 0.6748\n",
            "Epoch 10/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.5560 - accuracy: 0.7067 - val_loss: 0.5452 - val_accuracy: 0.7398\n",
            "Epoch 11/100\n",
            "62/62 [==============================] - 0s 8ms/step - loss: 0.5294 - accuracy: 0.7271 - val_loss: 0.5169 - val_accuracy: 0.7642\n",
            "Epoch 12/100\n",
            "62/62 [==============================] - 1s 10ms/step - loss: 0.5547 - accuracy: 0.7006 - val_loss: 0.4869 - val_accuracy: 0.8130\n",
            "Epoch 13/100\n",
            "62/62 [==============================] - 1s 8ms/step - loss: 0.5079 - accuracy: 0.7271 - val_loss: 0.5196 - val_accuracy: 0.7724\n",
            "Epoch 14/100\n",
            "62/62 [==============================] - 1s 10ms/step - loss: 0.5665 - accuracy: 0.7189 - val_loss: 0.5067 - val_accuracy: 0.8049\n",
            "Epoch 15/100\n",
            "62/62 [==============================] - 1s 9ms/step - loss: 0.5271 - accuracy: 0.7515 - val_loss: 0.4982 - val_accuracy: 0.7805\n",
            "Epoch 16/100\n",
            "62/62 [==============================] - 1s 10ms/step - loss: 0.5213 - accuracy: 0.7413 - val_loss: 0.4478 - val_accuracy: 0.8211\n",
            "Epoch 17/100\n",
            "62/62 [==============================] - 1s 10ms/step - loss: 0.5059 - accuracy: 0.7393 - val_loss: 0.4880 - val_accuracy: 0.7967\n",
            "Epoch 18/100\n",
            "62/62 [==============================] - 1s 9ms/step - loss: 0.5305 - accuracy: 0.7393 - val_loss: 0.6054 - val_accuracy: 0.6911\n",
            "Epoch 19/100\n",
            "62/62 [==============================] - 1s 9ms/step - loss: 0.5038 - accuracy: 0.7637 - val_loss: 0.4263 - val_accuracy: 0.8211\n",
            "Epoch 20/100\n",
            "62/62 [==============================] - 1s 10ms/step - loss: 0.5066 - accuracy: 0.7536 - val_loss: 0.5215 - val_accuracy: 0.7561\n",
            "Epoch 21/100\n",
            "62/62 [==============================] - 1s 12ms/step - loss: 0.5310 - accuracy: 0.7271 - val_loss: 0.4648 - val_accuracy: 0.7886\n",
            "Epoch 22/100\n",
            "62/62 [==============================] - 1s 11ms/step - loss: 0.5147 - accuracy: 0.7556 - val_loss: 0.4262 - val_accuracy: 0.8455\n",
            "Epoch 23/100\n",
            "62/62 [==============================] - 1s 13ms/step - loss: 0.5171 - accuracy: 0.7536 - val_loss: 0.4150 - val_accuracy: 0.8374\n",
            "Epoch 24/100\n",
            "62/62 [==============================] - 1s 13ms/step - loss: 0.4892 - accuracy: 0.7597 - val_loss: 0.5486 - val_accuracy: 0.7480\n",
            "Epoch 25/100\n",
            "62/62 [==============================] - 1s 14ms/step - loss: 0.4914 - accuracy: 0.7637 - val_loss: 0.4824 - val_accuracy: 0.7724\n",
            "Epoch 26/100\n",
            "62/62 [==============================] - 1s 18ms/step - loss: 0.5069 - accuracy: 0.7617 - val_loss: 0.4378 - val_accuracy: 0.7886\n",
            "Epoch 27/100\n",
            "62/62 [==============================] - 1s 14ms/step - loss: 0.5301 - accuracy: 0.7413 - val_loss: 0.4591 - val_accuracy: 0.8211\n",
            "Epoch 28/100\n",
            "62/62 [==============================] - 1s 17ms/step - loss: 0.4899 - accuracy: 0.7780 - val_loss: 0.4685 - val_accuracy: 0.7967\n",
            "Epoch 29/100\n",
            "62/62 [==============================] - 1s 15ms/step - loss: 0.5033 - accuracy: 0.7515 - val_loss: 0.4205 - val_accuracy: 0.8455\n",
            "Epoch 30/100\n",
            "62/62 [==============================] - 1s 9ms/step - loss: 0.5429 - accuracy: 0.7332 - val_loss: 0.5084 - val_accuracy: 0.6992\n",
            "Epoch 31/100\n",
            "62/62 [==============================] - 1s 10ms/step - loss: 0.5341 - accuracy: 0.7454 - val_loss: 0.4511 - val_accuracy: 0.8293\n",
            "Epoch 32/100\n",
            "62/62 [==============================] - 1s 10ms/step - loss: 0.4969 - accuracy: 0.7658 - val_loss: 0.4713 - val_accuracy: 0.8211\n",
            "Epoch 33/100\n",
            "62/62 [==============================] - 1s 9ms/step - loss: 0.4954 - accuracy: 0.7434 - val_loss: 0.5965 - val_accuracy: 0.6829\n",
            "Epoch 34/100\n",
            "62/62 [==============================] - 1s 11ms/step - loss: 0.5418 - accuracy: 0.7332 - val_loss: 0.4704 - val_accuracy: 0.8293\n",
            "Epoch 35/100\n",
            "62/62 [==============================] - 1s 11ms/step - loss: 0.5234 - accuracy: 0.7332 - val_loss: 0.4770 - val_accuracy: 0.7967\n",
            "Epoch 36/100\n",
            "62/62 [==============================] - 1s 10ms/step - loss: 0.5003 - accuracy: 0.7617 - val_loss: 0.4803 - val_accuracy: 0.7724\n",
            "Epoch 37/100\n",
            "62/62 [==============================] - 1s 11ms/step - loss: 0.5029 - accuracy: 0.7515 - val_loss: 0.4949 - val_accuracy: 0.7724\n",
            "Epoch 38/100\n",
            "62/62 [==============================] - 1s 9ms/step - loss: 0.5046 - accuracy: 0.7515 - val_loss: 0.5160 - val_accuracy: 0.7561\n",
            "Epoch 39/100\n",
            "62/62 [==============================] - 1s 11ms/step - loss: 0.4908 - accuracy: 0.7699 - val_loss: 0.5223 - val_accuracy: 0.7398\n",
            "Epoch 40/100\n",
            "62/62 [==============================] - 1s 11ms/step - loss: 0.4895 - accuracy: 0.7699 - val_loss: 0.4160 - val_accuracy: 0.8211\n",
            "Epoch 41/100\n",
            "62/62 [==============================] - 1s 8ms/step - loss: 0.5062 - accuracy: 0.7495 - val_loss: 0.4776 - val_accuracy: 0.7561\n",
            "Epoch 42/100\n",
            "62/62 [==============================] - 1s 16ms/step - loss: 0.4803 - accuracy: 0.7800 - val_loss: 0.4484 - val_accuracy: 0.8049\n",
            "Epoch 43/100\n",
            "62/62 [==============================] - 1s 10ms/step - loss: 0.4962 - accuracy: 0.7393 - val_loss: 0.4815 - val_accuracy: 0.7561\n",
            "Epoch 44/100\n",
            "62/62 [==============================] - 1s 12ms/step - loss: 0.4777 - accuracy: 0.7658 - val_loss: 0.5572 - val_accuracy: 0.7398\n",
            "Epoch 45/100\n",
            "62/62 [==============================] - 1s 15ms/step - loss: 0.4823 - accuracy: 0.7617 - val_loss: 0.4500 - val_accuracy: 0.8130\n",
            "Epoch 46/100\n",
            "62/62 [==============================] - 1s 8ms/step - loss: 0.4846 - accuracy: 0.7719 - val_loss: 0.4917 - val_accuracy: 0.7561\n",
            "Epoch 47/100\n",
            "62/62 [==============================] - 0s 8ms/step - loss: 0.4931 - accuracy: 0.7536 - val_loss: 0.4589 - val_accuracy: 0.8130\n",
            "Epoch 48/100\n",
            "62/62 [==============================] - 0s 8ms/step - loss: 0.5212 - accuracy: 0.7597 - val_loss: 0.4896 - val_accuracy: 0.7561\n",
            "Epoch 49/100\n",
            "62/62 [==============================] - 0s 8ms/step - loss: 0.4866 - accuracy: 0.7719 - val_loss: 0.6279 - val_accuracy: 0.7154\n",
            "Epoch 50/100\n",
            "62/62 [==============================] - 1s 8ms/step - loss: 0.4837 - accuracy: 0.7617 - val_loss: 0.4809 - val_accuracy: 0.7805\n",
            "Epoch 51/100\n",
            "62/62 [==============================] - 0s 8ms/step - loss: 0.4875 - accuracy: 0.7739 - val_loss: 0.5151 - val_accuracy: 0.7642\n",
            "Epoch 52/100\n",
            "62/62 [==============================] - 0s 8ms/step - loss: 0.4852 - accuracy: 0.7862 - val_loss: 0.4677 - val_accuracy: 0.7805\n",
            "Epoch 53/100\n",
            "62/62 [==============================] - 1s 8ms/step - loss: 0.5000 - accuracy: 0.7556 - val_loss: 0.5106 - val_accuracy: 0.7317\n",
            "Epoch 54/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.4923 - accuracy: 0.7556 - val_loss: 0.5305 - val_accuracy: 0.6911\n",
            "Epoch 55/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.4851 - accuracy: 0.7617 - val_loss: 0.5372 - val_accuracy: 0.7154\n",
            "Epoch 56/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.5212 - accuracy: 0.7251 - val_loss: 0.4914 - val_accuracy: 0.8374\n",
            "Epoch 57/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.5101 - accuracy: 0.7536 - val_loss: 0.5559 - val_accuracy: 0.7398\n",
            "Epoch 58/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.4824 - accuracy: 0.7882 - val_loss: 0.5560 - val_accuracy: 0.7724\n",
            "Epoch 59/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.4943 - accuracy: 0.7821 - val_loss: 0.5046 - val_accuracy: 0.7724\n",
            "Epoch 60/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.4854 - accuracy: 0.7699 - val_loss: 0.4676 - val_accuracy: 0.7886\n",
            "Epoch 61/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.4725 - accuracy: 0.7617 - val_loss: 0.5122 - val_accuracy: 0.7561\n",
            "Epoch 62/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.4919 - accuracy: 0.7556 - val_loss: 0.5221 - val_accuracy: 0.7398\n",
            "Epoch 63/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.4887 - accuracy: 0.7637 - val_loss: 0.5563 - val_accuracy: 0.7398\n",
            "Epoch 64/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.4890 - accuracy: 0.7597 - val_loss: 0.6253 - val_accuracy: 0.7154\n",
            "Epoch 65/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.5094 - accuracy: 0.7556 - val_loss: 0.4622 - val_accuracy: 0.8049\n",
            "Epoch 66/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.4896 - accuracy: 0.7617 - val_loss: 0.4999 - val_accuracy: 0.7561\n",
            "Epoch 67/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.5041 - accuracy: 0.7658 - val_loss: 0.4635 - val_accuracy: 0.8049\n",
            "Epoch 68/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.4609 - accuracy: 0.7678 - val_loss: 0.5307 - val_accuracy: 0.7480\n",
            "Epoch 69/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.5371 - accuracy: 0.7251 - val_loss: 0.4493 - val_accuracy: 0.8374\n",
            "Epoch 70/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.5005 - accuracy: 0.7536 - val_loss: 0.4470 - val_accuracy: 0.8130\n",
            "Epoch 71/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.4769 - accuracy: 0.7637 - val_loss: 0.4888 - val_accuracy: 0.7724\n",
            "Epoch 72/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.4856 - accuracy: 0.7800 - val_loss: 0.5397 - val_accuracy: 0.7480\n",
            "Epoch 73/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.5014 - accuracy: 0.7597 - val_loss: 0.5763 - val_accuracy: 0.7317\n",
            "Epoch 74/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.4785 - accuracy: 0.7678 - val_loss: 0.4651 - val_accuracy: 0.7805\n",
            "Epoch 75/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.4717 - accuracy: 0.7699 - val_loss: 0.4221 - val_accuracy: 0.8455\n",
            "Epoch 76/100\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.4698 - accuracy: 0.7617 - val_loss: 0.4757 - val_accuracy: 0.7805\n",
            "Epoch 77/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.4668 - accuracy: 0.7739 - val_loss: 0.4353 - val_accuracy: 0.8130\n",
            "Epoch 78/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.5663 - accuracy: 0.7291 - val_loss: 0.5162 - val_accuracy: 0.7480\n",
            "Epoch 79/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.4788 - accuracy: 0.7597 - val_loss: 0.4783 - val_accuracy: 0.8130\n",
            "Epoch 80/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.4772 - accuracy: 0.7678 - val_loss: 0.4680 - val_accuracy: 0.7886\n",
            "Epoch 81/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.4650 - accuracy: 0.7943 - val_loss: 0.5398 - val_accuracy: 0.7805\n",
            "Epoch 82/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.4683 - accuracy: 0.7719 - val_loss: 0.4487 - val_accuracy: 0.7967\n",
            "Epoch 83/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.5261 - accuracy: 0.7413 - val_loss: 0.5029 - val_accuracy: 0.7561\n",
            "Epoch 84/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.4714 - accuracy: 0.7739 - val_loss: 0.4793 - val_accuracy: 0.7642\n",
            "Epoch 85/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.4851 - accuracy: 0.7454 - val_loss: 0.5240 - val_accuracy: 0.7561\n",
            "Epoch 86/100\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.4735 - accuracy: 0.7780 - val_loss: 0.4421 - val_accuracy: 0.8049\n",
            "Epoch 87/100\n",
            "62/62 [==============================] - 0s 8ms/step - loss: 0.4850 - accuracy: 0.7678 - val_loss: 0.5347 - val_accuracy: 0.7398\n",
            "Epoch 88/100\n",
            "62/62 [==============================] - 0s 8ms/step - loss: 0.4925 - accuracy: 0.7658 - val_loss: 0.4441 - val_accuracy: 0.8130\n",
            "Epoch 89/100\n",
            "62/62 [==============================] - 1s 8ms/step - loss: 0.5227 - accuracy: 0.7332 - val_loss: 0.4403 - val_accuracy: 0.8374\n",
            "Epoch 90/100\n",
            "62/62 [==============================] - 1s 8ms/step - loss: 0.4918 - accuracy: 0.7536 - val_loss: 0.5294 - val_accuracy: 0.7480\n",
            "Epoch 91/100\n",
            "62/62 [==============================] - 1s 8ms/step - loss: 0.4859 - accuracy: 0.7556 - val_loss: 0.4732 - val_accuracy: 0.8211\n",
            "Epoch 92/100\n",
            "62/62 [==============================] - 0s 8ms/step - loss: 0.4862 - accuracy: 0.7658 - val_loss: 0.5227 - val_accuracy: 0.7724\n",
            "Epoch 93/100\n",
            "62/62 [==============================] - 1s 8ms/step - loss: 0.4770 - accuracy: 0.7678 - val_loss: 0.5291 - val_accuracy: 0.7398\n",
            "Epoch 94/100\n",
            "62/62 [==============================] - 0s 8ms/step - loss: 0.4739 - accuracy: 0.7760 - val_loss: 0.4673 - val_accuracy: 0.7886\n",
            "Epoch 95/100\n",
            "62/62 [==============================] - 0s 8ms/step - loss: 0.4695 - accuracy: 0.7576 - val_loss: 0.5358 - val_accuracy: 0.7480\n",
            "Epoch 96/100\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.5071 - accuracy: 0.7719 - val_loss: 0.4977 - val_accuracy: 0.7236\n",
            "Epoch 97/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.4872 - accuracy: 0.7495 - val_loss: 0.5167 - val_accuracy: 0.7561\n",
            "Epoch 98/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.4741 - accuracy: 0.7719 - val_loss: 0.5693 - val_accuracy: 0.7317\n",
            "Epoch 99/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.4690 - accuracy: 0.7882 - val_loss: 0.4703 - val_accuracy: 0.7805\n",
            "Epoch 100/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.4560 - accuracy: 0.7963 - val_loss: 0.5597 - val_accuracy: 0.7398\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7ff675d8e490>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_model.save(\"best_model_hp.h5\")"
      ],
      "metadata": {
        "id": "BbFIDJQ1qIq6"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss, accuracy = best_model.evaluate(X_test, y_test)\n",
        "print(\"Best model using Hyperparameter Tuning\")\n",
        "print(\"Loss: \", loss)\n",
        "print(\"Accuracy: \", accuracy)\n",
        "\n",
        "model = load_model(\"model.h5\")\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(\"Original model\")\n",
        "print(\"Loss: \", loss)\n",
        "print(\"Accuracy: \", accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D7KDfk3zasph",
        "outputId": "522a3750-d52b-4a92-ab5d-db85f53a4263"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6079 - accuracy: 0.7208\n",
            "Best model using Hyperparameter Tuning\n",
            "Loss:  0.6078561544418335\n",
            "Accuracy:  0.7207792401313782\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6241 - accuracy: 0.6753\n",
            "Original model\n",
            "Loss:  0.6241394877433777\n",
            "Accuracy:  0.6753246784210205\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### So với model ban đầu, model được cải tiến bằng Hyperparameter Tuning đã có sự cải thiện về độ chính xác. Sự thay đổi tạo ra từ việc các Hyperparameter đã được tối ưu có chọn lọc.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "9MahKuE4bT2P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Từ ban đầu model chỉ có 3 lớp với các thông số như sau:\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EAx5LFRucn3-",
        "outputId": "18b9846e-9e08-4ecc-cab7-f6c009a6fbab"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 8)                 72        \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 8)                 72        \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1)                 9         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 153\n",
            "Trainable params: 153\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Model sau khi được tối ưu có 6 lớp với các thông số sau:\n",
        "best_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k90Ukiu_dgZ2",
        "outputId": "443aa20a-f555-4ae7-87ba-d66eea02500c"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 56)                504       \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 40)                2280      \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 40)                1640      \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 64)                2624      \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 7,113\n",
            "Trainable params: 7,113\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sử dụng Regularization (L2 Regularization)"
      ],
      "metadata": {
        "id": "R7mCUbOYd7PI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import regularizers"
      ],
      "metadata": {
        "id": "LuZD0gZFeHKz"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#áp dụng  với hệ số lambda là 0.01 cho cả 2 lớp Dense đầu tiên của kiến trúc mạng neural. \n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(16, input_dim=8, activation='relu', kernel_regularizer=regularizers.l2(0.01)))\n",
        "model.add(Dense(8, activation='relu', kernel_regularizer=regularizers.l2(0.01)))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.fit(X_train, y_train, epochs=100, batch_size=8, validation_data=(X_val, y_val))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qtzygwGQeOVN",
        "outputId": "efb75e1d-c108-4635-8b1e-18a94c92bf36"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "62/62 [==============================] - 2s 8ms/step - loss: 14.4191 - accuracy: 0.5682 - val_loss: 3.6258 - val_accuracy: 0.4634\n",
            "Epoch 2/100\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 2.5798 - accuracy: 0.4786 - val_loss: 2.2378 - val_accuracy: 0.5122\n",
            "Epoch 3/100\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.7076 - accuracy: 0.5051 - val_loss: 1.7553 - val_accuracy: 0.4634\n",
            "Epoch 4/100\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.4406 - accuracy: 0.5682 - val_loss: 1.0810 - val_accuracy: 0.6423\n",
            "Epoch 5/100\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 1.1735 - accuracy: 0.5662 - val_loss: 0.9995 - val_accuracy: 0.6992\n",
            "Epoch 6/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 1.1195 - accuracy: 0.6171 - val_loss: 1.1195 - val_accuracy: 0.6179\n",
            "Epoch 7/100\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 1.0313 - accuracy: 0.5947 - val_loss: 0.9027 - val_accuracy: 0.7073\n",
            "Epoch 8/100\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 1.0055 - accuracy: 0.6008 - val_loss: 0.8753 - val_accuracy: 0.6992\n",
            "Epoch 9/100\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.0100 - accuracy: 0.5967 - val_loss: 0.9579 - val_accuracy: 0.7073\n",
            "Epoch 10/100\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 1.1020 - accuracy: 0.6110 - val_loss: 0.9131 - val_accuracy: 0.6911\n",
            "Epoch 11/100\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.9632 - accuracy: 0.6273 - val_loss: 0.8746 - val_accuracy: 0.7398\n",
            "Epoch 12/100\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.9594 - accuracy: 0.6293 - val_loss: 0.9545 - val_accuracy: 0.6667\n",
            "Epoch 13/100\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.9805 - accuracy: 0.6273 - val_loss: 1.2936 - val_accuracy: 0.6748\n",
            "Epoch 14/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.8803 - accuracy: 0.6477 - val_loss: 0.7909 - val_accuracy: 0.7480\n",
            "Epoch 15/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.8588 - accuracy: 0.6130 - val_loss: 1.0278 - val_accuracy: 0.5610\n",
            "Epoch 16/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.8640 - accuracy: 0.6578 - val_loss: 0.8045 - val_accuracy: 0.7236\n",
            "Epoch 17/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.9059 - accuracy: 0.6090 - val_loss: 0.8210 - val_accuracy: 0.7480\n",
            "Epoch 18/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.8868 - accuracy: 0.6253 - val_loss: 0.7929 - val_accuracy: 0.7317\n",
            "Epoch 19/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.8959 - accuracy: 0.6395 - val_loss: 0.9149 - val_accuracy: 0.6098\n",
            "Epoch 20/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.9298 - accuracy: 0.6375 - val_loss: 0.9273 - val_accuracy: 0.6423\n",
            "Epoch 21/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.8594 - accuracy: 0.6599 - val_loss: 0.8172 - val_accuracy: 0.7154\n",
            "Epoch 22/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.8237 - accuracy: 0.6558 - val_loss: 0.8094 - val_accuracy: 0.7317\n",
            "Epoch 23/100\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.7939 - accuracy: 0.6762 - val_loss: 0.9699 - val_accuracy: 0.6667\n",
            "Epoch 24/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 1.0048 - accuracy: 0.6273 - val_loss: 0.9493 - val_accuracy: 0.6667\n",
            "Epoch 25/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.8631 - accuracy: 0.6538 - val_loss: 0.9423 - val_accuracy: 0.6260\n",
            "Epoch 26/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.8497 - accuracy: 0.6293 - val_loss: 0.8765 - val_accuracy: 0.6341\n",
            "Epoch 27/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.8396 - accuracy: 0.6599 - val_loss: 0.7413 - val_accuracy: 0.7561\n",
            "Epoch 28/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.8036 - accuracy: 0.6497 - val_loss: 0.7862 - val_accuracy: 0.6992\n",
            "Epoch 29/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.8339 - accuracy: 0.6701 - val_loss: 0.8457 - val_accuracy: 0.6667\n",
            "Epoch 30/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.7839 - accuracy: 0.6599 - val_loss: 0.7353 - val_accuracy: 0.7561\n",
            "Epoch 31/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.7918 - accuracy: 0.6640 - val_loss: 0.7248 - val_accuracy: 0.7480\n",
            "Epoch 32/100\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.7993 - accuracy: 0.6538 - val_loss: 1.0494 - val_accuracy: 0.5366\n",
            "Epoch 33/100\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.7971 - accuracy: 0.6497 - val_loss: 0.7226 - val_accuracy: 0.7236\n",
            "Epoch 34/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.7563 - accuracy: 0.6884 - val_loss: 0.8112 - val_accuracy: 0.6992\n",
            "Epoch 35/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.7909 - accuracy: 0.6884 - val_loss: 0.9539 - val_accuracy: 0.5366\n",
            "Epoch 36/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.8613 - accuracy: 0.6640 - val_loss: 0.9714 - val_accuracy: 0.6504\n",
            "Epoch 37/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.7615 - accuracy: 0.6823 - val_loss: 0.8159 - val_accuracy: 0.6585\n",
            "Epoch 38/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.7653 - accuracy: 0.6823 - val_loss: 0.8507 - val_accuracy: 0.6748\n",
            "Epoch 39/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.7739 - accuracy: 0.6864 - val_loss: 0.8162 - val_accuracy: 0.6829\n",
            "Epoch 40/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.7414 - accuracy: 0.7088 - val_loss: 0.7585 - val_accuracy: 0.7073\n",
            "Epoch 41/100\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.8381 - accuracy: 0.6456 - val_loss: 0.7020 - val_accuracy: 0.7561\n",
            "Epoch 42/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.7833 - accuracy: 0.6884 - val_loss: 0.7394 - val_accuracy: 0.7236\n",
            "Epoch 43/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.7522 - accuracy: 0.6965 - val_loss: 0.7481 - val_accuracy: 0.7317\n",
            "Epoch 44/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.7207 - accuracy: 0.6864 - val_loss: 0.6975 - val_accuracy: 0.7236\n",
            "Epoch 45/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.7712 - accuracy: 0.7006 - val_loss: 0.6997 - val_accuracy: 0.7317\n",
            "Epoch 46/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.8034 - accuracy: 0.6741 - val_loss: 1.0073 - val_accuracy: 0.5366\n",
            "Epoch 47/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.7323 - accuracy: 0.6782 - val_loss: 0.9182 - val_accuracy: 0.5447\n",
            "Epoch 48/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.7736 - accuracy: 0.6925 - val_loss: 0.7203 - val_accuracy: 0.7154\n",
            "Epoch 49/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.7535 - accuracy: 0.6762 - val_loss: 0.7020 - val_accuracy: 0.7398\n",
            "Epoch 50/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.7268 - accuracy: 0.7108 - val_loss: 0.6780 - val_accuracy: 0.7724\n",
            "Epoch 51/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.7753 - accuracy: 0.6986 - val_loss: 0.7392 - val_accuracy: 0.7154\n",
            "Epoch 52/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.7364 - accuracy: 0.6945 - val_loss: 0.6717 - val_accuracy: 0.7886\n",
            "Epoch 53/100\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.7386 - accuracy: 0.6762 - val_loss: 0.6860 - val_accuracy: 0.7642\n",
            "Epoch 54/100\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.6972 - accuracy: 0.7108 - val_loss: 0.7189 - val_accuracy: 0.7236\n",
            "Epoch 55/100\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.7250 - accuracy: 0.6884 - val_loss: 0.6567 - val_accuracy: 0.7967\n",
            "Epoch 56/100\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.7028 - accuracy: 0.6986 - val_loss: 0.6723 - val_accuracy: 0.7805\n",
            "Epoch 57/100\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.7863 - accuracy: 0.6843 - val_loss: 0.7515 - val_accuracy: 0.6829\n",
            "Epoch 58/100\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.6870 - accuracy: 0.7210 - val_loss: 0.6626 - val_accuracy: 0.7805\n",
            "Epoch 59/100\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.6652 - accuracy: 0.7271 - val_loss: 0.6851 - val_accuracy: 0.7317\n",
            "Epoch 60/100\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.7754 - accuracy: 0.6517 - val_loss: 0.7271 - val_accuracy: 0.7317\n",
            "Epoch 61/100\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.7048 - accuracy: 0.6965 - val_loss: 0.7159 - val_accuracy: 0.7398\n",
            "Epoch 62/100\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.6858 - accuracy: 0.7026 - val_loss: 0.6526 - val_accuracy: 0.7642\n",
            "Epoch 63/100\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.7281 - accuracy: 0.7026 - val_loss: 0.8096 - val_accuracy: 0.6585\n",
            "Epoch 64/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.7258 - accuracy: 0.6925 - val_loss: 0.6621 - val_accuracy: 0.7642\n",
            "Epoch 65/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.6980 - accuracy: 0.7006 - val_loss: 0.6598 - val_accuracy: 0.7561\n",
            "Epoch 66/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.7363 - accuracy: 0.6945 - val_loss: 1.6633 - val_accuracy: 0.4146\n",
            "Epoch 67/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.7769 - accuracy: 0.6782 - val_loss: 0.6463 - val_accuracy: 0.7886\n",
            "Epoch 68/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.7369 - accuracy: 0.6864 - val_loss: 0.7091 - val_accuracy: 0.7480\n",
            "Epoch 69/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.6919 - accuracy: 0.7088 - val_loss: 0.7140 - val_accuracy: 0.7480\n",
            "Epoch 70/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.7321 - accuracy: 0.6925 - val_loss: 0.6901 - val_accuracy: 0.7073\n",
            "Epoch 71/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.6800 - accuracy: 0.6986 - val_loss: 0.6327 - val_accuracy: 0.7805\n",
            "Epoch 72/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.6715 - accuracy: 0.7352 - val_loss: 0.8180 - val_accuracy: 0.6585\n",
            "Epoch 73/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.7413 - accuracy: 0.7006 - val_loss: 0.6890 - val_accuracy: 0.7561\n",
            "Epoch 74/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.6880 - accuracy: 0.7006 - val_loss: 0.6523 - val_accuracy: 0.7724\n",
            "Epoch 75/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.6769 - accuracy: 0.7271 - val_loss: 0.6260 - val_accuracy: 0.7886\n",
            "Epoch 76/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.6369 - accuracy: 0.7454 - val_loss: 0.6274 - val_accuracy: 0.7805\n",
            "Epoch 77/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.7360 - accuracy: 0.6884 - val_loss: 0.6717 - val_accuracy: 0.7480\n",
            "Epoch 78/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.6912 - accuracy: 0.7169 - val_loss: 0.6913 - val_accuracy: 0.7317\n",
            "Epoch 79/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.7184 - accuracy: 0.7006 - val_loss: 0.6357 - val_accuracy: 0.7886\n",
            "Epoch 80/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.6555 - accuracy: 0.7434 - val_loss: 0.6447 - val_accuracy: 0.7642\n",
            "Epoch 81/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.6619 - accuracy: 0.7291 - val_loss: 0.6844 - val_accuracy: 0.7724\n",
            "Epoch 82/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.6635 - accuracy: 0.7271 - val_loss: 0.6312 - val_accuracy: 0.7480\n",
            "Epoch 83/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.6508 - accuracy: 0.7149 - val_loss: 0.6748 - val_accuracy: 0.7561\n",
            "Epoch 84/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.6847 - accuracy: 0.7006 - val_loss: 0.6334 - val_accuracy: 0.7724\n",
            "Epoch 85/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.6996 - accuracy: 0.7088 - val_loss: 0.6263 - val_accuracy: 0.7886\n",
            "Epoch 86/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.6766 - accuracy: 0.7108 - val_loss: 0.7366 - val_accuracy: 0.6992\n",
            "Epoch 87/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.6481 - accuracy: 0.7373 - val_loss: 0.6141 - val_accuracy: 0.8049\n",
            "Epoch 88/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.6283 - accuracy: 0.7312 - val_loss: 0.6425 - val_accuracy: 0.7642\n",
            "Epoch 89/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.6669 - accuracy: 0.6986 - val_loss: 0.6080 - val_accuracy: 0.8130\n",
            "Epoch 90/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.6667 - accuracy: 0.7413 - val_loss: 0.6071 - val_accuracy: 0.8130\n",
            "Epoch 91/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.7337 - accuracy: 0.6599 - val_loss: 0.9345 - val_accuracy: 0.6585\n",
            "Epoch 92/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.6762 - accuracy: 0.7291 - val_loss: 0.6337 - val_accuracy: 0.7561\n",
            "Epoch 93/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.6503 - accuracy: 0.7230 - val_loss: 0.6954 - val_accuracy: 0.7317\n",
            "Epoch 94/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.8192 - accuracy: 0.6823 - val_loss: 0.8725 - val_accuracy: 0.6829\n",
            "Epoch 95/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.7427 - accuracy: 0.7026 - val_loss: 0.6589 - val_accuracy: 0.7805\n",
            "Epoch 96/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.6813 - accuracy: 0.7189 - val_loss: 0.7135 - val_accuracy: 0.7317\n",
            "Epoch 97/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.6584 - accuracy: 0.7251 - val_loss: 0.9003 - val_accuracy: 0.5610\n",
            "Epoch 98/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.6884 - accuracy: 0.7128 - val_loss: 0.6843 - val_accuracy: 0.7317\n",
            "Epoch 99/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.6610 - accuracy: 0.7230 - val_loss: 0.6146 - val_accuracy: 0.7724\n",
            "Epoch 100/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.6648 - accuracy: 0.7271 - val_loss: 0.6580 - val_accuracy: 0.7398\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7ff675d43040>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"best_model_regularization.h5\")"
      ],
      "metadata": {
        "id": "wKHLMPeWqT6S"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(\"Best model using Regularization (L2 Regularization)\")\n",
        "print(\"Loss: \", loss)\n",
        "print(\"Accuracy: \", accuracy)\n",
        "\n",
        "original = load_model(\"model.h5\")\n",
        "loss, accuracy = original.evaluate(X_test, y_test)\n",
        "print(\"Original model\")\n",
        "print(\"Loss: \", loss)\n",
        "print(\"Accuracy: \", accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kmmpHoXae4XB",
        "outputId": "e67b662a-1aad-4049-b757-04e729d3027d"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6683 - accuracy: 0.7468\n",
            "Best model using Regularization (L2 Regularization)\n",
            "Loss:  0.668339729309082\n",
            "Accuracy:  0.7467532753944397\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6241 - accuracy: 0.6753\n",
            "Original model\n",
            "Loss:  0.6241394877433777\n",
            "Accuracy:  0.6753246784210205\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### So với model ban đầu, model được cải tiến bằng Regularization đã có sự thay đổi về độ chính xác, cụ thể ở đây em dùng kỹ thuật L2 Regularization. Sự thay đổi tạo ra từ việc thêm một thành phần bình phương của các trọng số vào hàm mất mát. Việc này sẽ làm cho các trọng số nhỏ hơn, dẫn đến mô hình đơn giản hơn và tránh được việc bị overfitting."
      ],
      "metadata": {
        "id": "KfyDN-5Cf0zY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sử dụng Optimization (Adam -> RMSprop)"
      ],
      "metadata": {
        "id": "3bqYas4liwU6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(16, input_dim=8, activation='relu', kernel_regularizer=regularizers.l2(0.01)))\n",
        "model.add(Dense(8, activation='relu', kernel_regularizer=regularizers.l2(0.01)))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer=RMSprop(learning_rate=0.001), metrics=['accuracy'])\n",
        "model.fit(X_train, y_train, epochs=100, batch_size=8, validation_data=(X_val, y_val))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-XjBSfcjifxc",
        "outputId": "00bd1d2d-632b-4ccd-aa0a-93ea93c19916"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "62/62 [==============================] - 2s 22ms/step - loss: 2.0201 - accuracy: 0.5804 - val_loss: 1.2111 - val_accuracy: 0.6179\n",
            "Epoch 2/100\n",
            "62/62 [==============================] - 1s 18ms/step - loss: 1.2378 - accuracy: 0.6191 - val_loss: 1.0195 - val_accuracy: 0.6341\n",
            "Epoch 3/100\n",
            "62/62 [==============================] - 1s 15ms/step - loss: 1.1141 - accuracy: 0.6334 - val_loss: 0.9428 - val_accuracy: 0.6829\n",
            "Epoch 4/100\n",
            "62/62 [==============================] - 1s 10ms/step - loss: 1.0406 - accuracy: 0.6334 - val_loss: 0.9200 - val_accuracy: 0.6504\n",
            "Epoch 5/100\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.9704 - accuracy: 0.6395 - val_loss: 0.8856 - val_accuracy: 0.6748\n",
            "Epoch 6/100\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.9278 - accuracy: 0.6538 - val_loss: 0.8831 - val_accuracy: 0.6585\n",
            "Epoch 7/100\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.8818 - accuracy: 0.6640 - val_loss: 0.8558 - val_accuracy: 0.6667\n",
            "Epoch 8/100\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.8803 - accuracy: 0.6456 - val_loss: 0.8619 - val_accuracy: 0.6423\n",
            "Epoch 9/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.8607 - accuracy: 0.6517 - val_loss: 0.9272 - val_accuracy: 0.6423\n",
            "Epoch 10/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.8268 - accuracy: 0.6477 - val_loss: 0.8296 - val_accuracy: 0.6423\n",
            "Epoch 11/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.8208 - accuracy: 0.6558 - val_loss: 0.8246 - val_accuracy: 0.6504\n",
            "Epoch 12/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.8095 - accuracy: 0.6680 - val_loss: 0.8012 - val_accuracy: 0.6423\n",
            "Epoch 13/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.8194 - accuracy: 0.6415 - val_loss: 0.8017 - val_accuracy: 0.6667\n",
            "Epoch 14/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.7952 - accuracy: 0.6640 - val_loss: 0.7488 - val_accuracy: 0.6667\n",
            "Epoch 15/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.7999 - accuracy: 0.6456 - val_loss: 0.7493 - val_accuracy: 0.6585\n",
            "Epoch 16/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.7782 - accuracy: 0.6477 - val_loss: 0.7877 - val_accuracy: 0.6423\n",
            "Epoch 17/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.7685 - accuracy: 0.6538 - val_loss: 0.7572 - val_accuracy: 0.6585\n",
            "Epoch 18/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.7437 - accuracy: 0.6599 - val_loss: 0.7284 - val_accuracy: 0.6911\n",
            "Epoch 19/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.7532 - accuracy: 0.6741 - val_loss: 0.7829 - val_accuracy: 0.6992\n",
            "Epoch 20/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.7435 - accuracy: 0.6680 - val_loss: 0.6955 - val_accuracy: 0.7073\n",
            "Epoch 21/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.7363 - accuracy: 0.6741 - val_loss: 0.6917 - val_accuracy: 0.6992\n",
            "Epoch 22/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.7111 - accuracy: 0.6945 - val_loss: 0.6934 - val_accuracy: 0.7154\n",
            "Epoch 23/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.7148 - accuracy: 0.7006 - val_loss: 0.6834 - val_accuracy: 0.7073\n",
            "Epoch 24/100\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.7011 - accuracy: 0.7067 - val_loss: 0.6790 - val_accuracy: 0.7073\n",
            "Epoch 25/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.6913 - accuracy: 0.6925 - val_loss: 0.6700 - val_accuracy: 0.6667\n",
            "Epoch 26/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.6930 - accuracy: 0.7026 - val_loss: 0.7736 - val_accuracy: 0.7073\n",
            "Epoch 27/100\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.7036 - accuracy: 0.6843 - val_loss: 0.6699 - val_accuracy: 0.6829\n",
            "Epoch 28/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.6914 - accuracy: 0.6904 - val_loss: 0.6642 - val_accuracy: 0.6992\n",
            "Epoch 29/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.6895 - accuracy: 0.6904 - val_loss: 0.6645 - val_accuracy: 0.7317\n",
            "Epoch 30/100\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.6818 - accuracy: 0.7128 - val_loss: 0.6872 - val_accuracy: 0.6992\n",
            "Epoch 31/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.6786 - accuracy: 0.6986 - val_loss: 0.6755 - val_accuracy: 0.6992\n",
            "Epoch 32/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.6811 - accuracy: 0.7108 - val_loss: 0.7450 - val_accuracy: 0.6667\n",
            "Epoch 33/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.6834 - accuracy: 0.7006 - val_loss: 0.6942 - val_accuracy: 0.7154\n",
            "Epoch 34/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.6725 - accuracy: 0.7088 - val_loss: 0.7079 - val_accuracy: 0.6911\n",
            "Epoch 35/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.6695 - accuracy: 0.7251 - val_loss: 0.6562 - val_accuracy: 0.6748\n",
            "Epoch 36/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.6808 - accuracy: 0.7006 - val_loss: 0.6463 - val_accuracy: 0.7236\n",
            "Epoch 37/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.6683 - accuracy: 0.7026 - val_loss: 0.6408 - val_accuracy: 0.7480\n",
            "Epoch 38/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.6674 - accuracy: 0.7128 - val_loss: 0.6454 - val_accuracy: 0.6829\n",
            "Epoch 39/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.6657 - accuracy: 0.7108 - val_loss: 0.6722 - val_accuracy: 0.7073\n",
            "Epoch 40/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.6588 - accuracy: 0.7088 - val_loss: 0.6709 - val_accuracy: 0.6992\n",
            "Epoch 41/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.6641 - accuracy: 0.7210 - val_loss: 0.7024 - val_accuracy: 0.6992\n",
            "Epoch 42/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.6574 - accuracy: 0.7189 - val_loss: 0.6352 - val_accuracy: 0.6992\n",
            "Epoch 43/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.6462 - accuracy: 0.7291 - val_loss: 0.6496 - val_accuracy: 0.7561\n",
            "Epoch 44/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.6566 - accuracy: 0.7230 - val_loss: 0.6753 - val_accuracy: 0.7073\n",
            "Epoch 45/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.6600 - accuracy: 0.7291 - val_loss: 0.6730 - val_accuracy: 0.6911\n",
            "Epoch 46/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.6544 - accuracy: 0.7169 - val_loss: 0.6546 - val_accuracy: 0.6829\n",
            "Epoch 47/100\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.6606 - accuracy: 0.7026 - val_loss: 0.6518 - val_accuracy: 0.7154\n",
            "Epoch 48/100\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.6429 - accuracy: 0.7230 - val_loss: 0.7181 - val_accuracy: 0.6829\n",
            "Epoch 49/100\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.6527 - accuracy: 0.7088 - val_loss: 0.6260 - val_accuracy: 0.7154\n",
            "Epoch 50/100\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.6524 - accuracy: 0.7047 - val_loss: 0.6224 - val_accuracy: 0.7154\n",
            "Epoch 51/100\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.6485 - accuracy: 0.7210 - val_loss: 0.6190 - val_accuracy: 0.7154\n",
            "Epoch 52/100\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.6518 - accuracy: 0.7230 - val_loss: 0.6465 - val_accuracy: 0.7398\n",
            "Epoch 53/100\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.6530 - accuracy: 0.7230 - val_loss: 0.6384 - val_accuracy: 0.6992\n",
            "Epoch 54/100\n",
            "62/62 [==============================] - 0s 8ms/step - loss: 0.6499 - accuracy: 0.7251 - val_loss: 0.6225 - val_accuracy: 0.7073\n",
            "Epoch 55/100\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.6410 - accuracy: 0.7251 - val_loss: 0.6502 - val_accuracy: 0.6911\n",
            "Epoch 56/100\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.6453 - accuracy: 0.7169 - val_loss: 0.6461 - val_accuracy: 0.7236\n",
            "Epoch 57/100\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.6407 - accuracy: 0.7230 - val_loss: 0.6099 - val_accuracy: 0.7317\n",
            "Epoch 58/100\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.6396 - accuracy: 0.7230 - val_loss: 0.6276 - val_accuracy: 0.7317\n",
            "Epoch 59/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.6436 - accuracy: 0.7271 - val_loss: 0.6593 - val_accuracy: 0.7398\n",
            "Epoch 60/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.6507 - accuracy: 0.7169 - val_loss: 0.6332 - val_accuracy: 0.6992\n",
            "Epoch 61/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.6438 - accuracy: 0.7251 - val_loss: 0.6070 - val_accuracy: 0.7154\n",
            "Epoch 62/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.6367 - accuracy: 0.7332 - val_loss: 0.6037 - val_accuracy: 0.7154\n",
            "Epoch 63/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.6340 - accuracy: 0.7230 - val_loss: 0.6373 - val_accuracy: 0.7317\n",
            "Epoch 64/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.6476 - accuracy: 0.7108 - val_loss: 0.6220 - val_accuracy: 0.7154\n",
            "Epoch 65/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.6432 - accuracy: 0.7291 - val_loss: 0.6092 - val_accuracy: 0.6992\n",
            "Epoch 66/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.6328 - accuracy: 0.7169 - val_loss: 0.6427 - val_accuracy: 0.7480\n",
            "Epoch 67/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.6489 - accuracy: 0.7251 - val_loss: 0.5963 - val_accuracy: 0.7236\n",
            "Epoch 68/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.6356 - accuracy: 0.7373 - val_loss: 0.6062 - val_accuracy: 0.7073\n",
            "Epoch 69/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.6234 - accuracy: 0.7434 - val_loss: 0.6005 - val_accuracy: 0.7642\n",
            "Epoch 70/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.6389 - accuracy: 0.7189 - val_loss: 0.6170 - val_accuracy: 0.7398\n",
            "Epoch 71/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.6364 - accuracy: 0.7149 - val_loss: 0.6055 - val_accuracy: 0.7236\n",
            "Epoch 72/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.6259 - accuracy: 0.7312 - val_loss: 0.5979 - val_accuracy: 0.7236\n",
            "Epoch 73/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.6248 - accuracy: 0.7271 - val_loss: 0.6451 - val_accuracy: 0.7480\n",
            "Epoch 74/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.6324 - accuracy: 0.7210 - val_loss: 0.6013 - val_accuracy: 0.7561\n",
            "Epoch 75/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.6224 - accuracy: 0.7230 - val_loss: 0.6802 - val_accuracy: 0.6992\n",
            "Epoch 76/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.6222 - accuracy: 0.7271 - val_loss: 0.6178 - val_accuracy: 0.7317\n",
            "Epoch 77/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.6223 - accuracy: 0.7230 - val_loss: 0.6287 - val_accuracy: 0.7398\n",
            "Epoch 78/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.6286 - accuracy: 0.7291 - val_loss: 0.5985 - val_accuracy: 0.7317\n",
            "Epoch 79/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.6304 - accuracy: 0.7108 - val_loss: 0.6188 - val_accuracy: 0.6992\n",
            "Epoch 80/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.6181 - accuracy: 0.7251 - val_loss: 0.6213 - val_accuracy: 0.7154\n",
            "Epoch 81/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.6254 - accuracy: 0.7271 - val_loss: 0.6345 - val_accuracy: 0.7236\n",
            "Epoch 82/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.6192 - accuracy: 0.7393 - val_loss: 0.6030 - val_accuracy: 0.7317\n",
            "Epoch 83/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.6230 - accuracy: 0.7271 - val_loss: 0.6209 - val_accuracy: 0.7480\n",
            "Epoch 84/100\n",
            "62/62 [==============================] - 0s 3ms/step - loss: 0.6272 - accuracy: 0.7332 - val_loss: 0.6091 - val_accuracy: 0.7317\n",
            "Epoch 85/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.6267 - accuracy: 0.7332 - val_loss: 0.5893 - val_accuracy: 0.7480\n",
            "Epoch 86/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.6259 - accuracy: 0.7210 - val_loss: 0.6373 - val_accuracy: 0.7073\n",
            "Epoch 87/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.6213 - accuracy: 0.7189 - val_loss: 0.5931 - val_accuracy: 0.7480\n",
            "Epoch 88/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.6153 - accuracy: 0.7210 - val_loss: 0.6320 - val_accuracy: 0.7398\n",
            "Epoch 89/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.6102 - accuracy: 0.7291 - val_loss: 0.5700 - val_accuracy: 0.7317\n",
            "Epoch 90/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.6106 - accuracy: 0.7251 - val_loss: 0.7238 - val_accuracy: 0.7317\n",
            "Epoch 91/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.6255 - accuracy: 0.7230 - val_loss: 0.5936 - val_accuracy: 0.7398\n",
            "Epoch 92/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.6183 - accuracy: 0.7271 - val_loss: 0.5701 - val_accuracy: 0.7480\n",
            "Epoch 93/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.6113 - accuracy: 0.7189 - val_loss: 0.6005 - val_accuracy: 0.7480\n",
            "Epoch 94/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.6176 - accuracy: 0.7312 - val_loss: 0.6030 - val_accuracy: 0.7398\n",
            "Epoch 95/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.6229 - accuracy: 0.7352 - val_loss: 0.5933 - val_accuracy: 0.7398\n",
            "Epoch 96/100\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.6211 - accuracy: 0.7271 - val_loss: 0.6209 - val_accuracy: 0.7561\n",
            "Epoch 97/100\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.6130 - accuracy: 0.7373 - val_loss: 0.6149 - val_accuracy: 0.7561\n",
            "Epoch 98/100\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.6213 - accuracy: 0.7332 - val_loss: 0.5966 - val_accuracy: 0.7236\n",
            "Epoch 99/100\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.6116 - accuracy: 0.7373 - val_loss: 0.5896 - val_accuracy: 0.7642\n",
            "Epoch 100/100\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.6151 - accuracy: 0.7230 - val_loss: 0.5822 - val_accuracy: 0.7561\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7ff6775b4a90>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"best_model_optimization.h5\")"
      ],
      "metadata": {
        "id": "ETd2_XspqkiK"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(\"Best model using Optimization (Adam -> RMSprop)\")\n",
        "print(\"Loss: \", loss)\n",
        "print(\"Accuracy: \", accuracy)\n",
        "\n",
        "original = load_model(\"model.h5\")\n",
        "loss, accuracy = original.evaluate(X_test, y_test)\n",
        "print(\"Original model\")\n",
        "print(\"Loss: \", loss)\n",
        "print(\"Accuracy: \", accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4-4C4kRMi2hj",
        "outputId": "9ec620f3-a18b-49b1-ee51-278390454e59"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6644 - accuracy: 0.7468\n",
            "Best model using Optimization (Adam -> RMSprop)\n",
            "Loss:  0.6643891930580139\n",
            "Accuracy:  0.7467532753944397\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6241 - accuracy: 0.6753\n",
            "Original model\n",
            "Loss:  0.6241394877433777\n",
            "Accuracy:  0.6753246784210205\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### So với model ban đầu, model được cải tiến bằng Regularization đã có sự thay đổi về độ chính xác, cụ thể ở đây em thay đổi optimizer từ Adam sang RMSprop. Thuật toán tối ưu mô hình sẽ thay đổi cách tính toán gradient và cập nhật trọng số trong quá trình huấn luyện. Cụ thể, hai thuật toán này sử dụng hai phương pháp khác nhau để tính toán gradient và cập nhật trọng số, do đó việc thay đổi optimizer sẽ có tác động đến hiệu suất của mô hình."
      ],
      "metadata": {
        "id": "6O_FsWg_jHwn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Kết hợp cả 3 kỹ thuật"
      ],
      "metadata": {
        "id": "DgCWjPexjbb6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tạm hàm build Hyper model\n",
        "def build_best_model(hp): \n",
        "  model = keras.Sequential()\n",
        "\n",
        "  X = hp.Int('units_input', min_value=8, max_value=64, step=8)\n",
        "  model.add(Dense(units=X, input_dim=8, activation='relu', kernel_regularizer=regularizers.l2(0.01)))\n",
        "\n",
        "  for i in range(hp.Int('num_layers', 1, 4)):\n",
        "    Y = hp.Int('units_' + str(i), min_value=8, max_value=64, step=8)\n",
        "    model.add(Dense(units=Y, activation='relu', kernel_regularizer=regularizers.l2(0.01)))\n",
        "\n",
        "  model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "  # Tìm kiếm optimizer\n",
        "  optimizer = hp.Choice('optimizer', values=['adam', 'rmsprop'])\n",
        "\n",
        "  # Tìm kiếm learning_rate\n",
        "  lr = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
        "\n",
        "  if optimizer == 'adam':\n",
        "    model.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=lr), metrics=['accuracy'])\n",
        "  else:\n",
        "    model.compile(loss='binary_crossentropy', optimizer=RMSprop(learning_rate=lr), metrics=['accuracy'])\n",
        "  \n",
        "  return model"
      ],
      "metadata": {
        "id": "OITYCSdPjqO7"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Khởi tạo Tuner\n",
        "tuner = kt.Hyperband (build_best_model, objective=\"val_accuracy\", directory=\"tuner_dir_2\", project_name=\"MLE501_Tuner_2\")"
      ],
      "metadata": {
        "id": "_GVRQIGJlOds"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tuner.search(X_train, y_train, epochs=10, validation_data=(X_val, y_val))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RxCcOO_DlXuw",
        "outputId": "c31167d4-c004-4042-b0a3-0ec3881ad417"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 254 Complete [00h 00m 22s]\n",
            "val_accuracy: 0.8292682766914368\n",
            "\n",
            "Best val_accuracy So Far: 0.869918704032898\n",
            "Total elapsed time: 00h 16m 54s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Lấy ra các tham số\n",
        "best_hps = tuner.get_best_hyperparameters()[0]\n",
        "\n",
        "print(\"units_input: \", best_hps.get('units_input'))\n",
        "print(\"num_layers: \", best_hps.get('num_layers'))\n",
        "print(\"optimizer: \", best_hps.get('optimizer'))\n",
        "print(\"learning_rate: \", best_hps.get('learning_rate'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jmvaw6wOpV4j",
        "outputId": "f6e00bc9-561b-43c6-c7e9-95dfa7a46649"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "units_input:  8\n",
            "num_layers:  3\n",
            "optimizer:  adam\n",
            "learning_rate:  0.01\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# lấy super model\n",
        "best_model = tuner.get_best_models(num_models=1)[0]\n",
        "\n",
        "best_model.summary()\n",
        "\n",
        "best_model.fit(X_train, y_train, epochs=100, batch_size=8, validation_data=(X_val, y_val))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MuqUmmfWquFv",
        "outputId": "4e9c5a12-ffbe-41ed-f7f0-12dad34b9983"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 8)                 72        \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 8)                 72        \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 32)                288       \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 8)                 264       \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 1)                 9         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 705\n",
            "Trainable params: 705\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "62/62 [==============================] - 2s 10ms/step - loss: 0.5937 - accuracy: 0.6986 - val_loss: 0.5208 - val_accuracy: 0.8211\n",
            "Epoch 2/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.5800 - accuracy: 0.6965 - val_loss: 0.4816 - val_accuracy: 0.8374\n",
            "Epoch 3/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.5781 - accuracy: 0.7332 - val_loss: 0.5087 - val_accuracy: 0.7805\n",
            "Epoch 4/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.5647 - accuracy: 0.7230 - val_loss: 0.4953 - val_accuracy: 0.8049\n",
            "Epoch 5/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.5912 - accuracy: 0.7067 - val_loss: 0.4982 - val_accuracy: 0.7561\n",
            "Epoch 6/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.5538 - accuracy: 0.7475 - val_loss: 0.4955 - val_accuracy: 0.7642\n",
            "Epoch 7/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.5584 - accuracy: 0.7454 - val_loss: 0.5618 - val_accuracy: 0.7154\n",
            "Epoch 8/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.5725 - accuracy: 0.7332 - val_loss: 0.4817 - val_accuracy: 0.8049\n",
            "Epoch 9/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.5721 - accuracy: 0.7251 - val_loss: 0.4745 - val_accuracy: 0.8537\n",
            "Epoch 10/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.5437 - accuracy: 0.7413 - val_loss: 0.4632 - val_accuracy: 0.8455\n",
            "Epoch 11/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.5676 - accuracy: 0.7149 - val_loss: 0.5799 - val_accuracy: 0.7154\n",
            "Epoch 12/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.5399 - accuracy: 0.7454 - val_loss: 0.5265 - val_accuracy: 0.6992\n",
            "Epoch 13/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.5789 - accuracy: 0.7067 - val_loss: 0.4661 - val_accuracy: 0.8455\n",
            "Epoch 14/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.5534 - accuracy: 0.7291 - val_loss: 0.4676 - val_accuracy: 0.8455\n",
            "Epoch 15/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.5553 - accuracy: 0.7189 - val_loss: 0.4721 - val_accuracy: 0.8537\n",
            "Epoch 16/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.5437 - accuracy: 0.7251 - val_loss: 0.4616 - val_accuracy: 0.8537\n",
            "Epoch 17/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.5342 - accuracy: 0.7393 - val_loss: 0.4424 - val_accuracy: 0.8537\n",
            "Epoch 18/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.5422 - accuracy: 0.7413 - val_loss: 0.4669 - val_accuracy: 0.7886\n",
            "Epoch 19/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.5606 - accuracy: 0.7271 - val_loss: 0.4400 - val_accuracy: 0.8455\n",
            "Epoch 20/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.5571 - accuracy: 0.7189 - val_loss: 0.4794 - val_accuracy: 0.8049\n",
            "Epoch 21/100\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.5447 - accuracy: 0.7413 - val_loss: 0.4633 - val_accuracy: 0.8049\n",
            "Epoch 22/100\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.5482 - accuracy: 0.7352 - val_loss: 0.4424 - val_accuracy: 0.8293\n",
            "Epoch 23/100\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.5450 - accuracy: 0.7271 - val_loss: 0.4825 - val_accuracy: 0.7724\n",
            "Epoch 24/100\n",
            "62/62 [==============================] - 0s 8ms/step - loss: 0.5544 - accuracy: 0.7434 - val_loss: 0.5264 - val_accuracy: 0.7317\n",
            "Epoch 25/100\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.5748 - accuracy: 0.7047 - val_loss: 0.4947 - val_accuracy: 0.7317\n",
            "Epoch 26/100\n",
            "62/62 [==============================] - 1s 8ms/step - loss: 0.5621 - accuracy: 0.7088 - val_loss: 0.4713 - val_accuracy: 0.7967\n",
            "Epoch 27/100\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.5577 - accuracy: 0.7128 - val_loss: 0.4868 - val_accuracy: 0.7886\n",
            "Epoch 28/100\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.5316 - accuracy: 0.7312 - val_loss: 0.4552 - val_accuracy: 0.8211\n",
            "Epoch 29/100\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.5309 - accuracy: 0.7556 - val_loss: 0.4670 - val_accuracy: 0.7886\n",
            "Epoch 30/100\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.5531 - accuracy: 0.7332 - val_loss: 0.4527 - val_accuracy: 0.8293\n",
            "Epoch 31/100\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.5478 - accuracy: 0.7475 - val_loss: 0.4473 - val_accuracy: 0.8211\n",
            "Epoch 32/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.5372 - accuracy: 0.7210 - val_loss: 0.4463 - val_accuracy: 0.8293\n",
            "Epoch 33/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.5547 - accuracy: 0.7088 - val_loss: 0.4701 - val_accuracy: 0.8537\n",
            "Epoch 34/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.5661 - accuracy: 0.7291 - val_loss: 0.5073 - val_accuracy: 0.7967\n",
            "Epoch 35/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.5364 - accuracy: 0.7413 - val_loss: 0.4437 - val_accuracy: 0.8374\n",
            "Epoch 36/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.5334 - accuracy: 0.7189 - val_loss: 0.4483 - val_accuracy: 0.8374\n",
            "Epoch 37/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.5227 - accuracy: 0.7495 - val_loss: 0.4374 - val_accuracy: 0.8374\n",
            "Epoch 38/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.5431 - accuracy: 0.7189 - val_loss: 0.4567 - val_accuracy: 0.8374\n",
            "Epoch 39/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.5484 - accuracy: 0.7393 - val_loss: 0.5585 - val_accuracy: 0.7154\n",
            "Epoch 40/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.5414 - accuracy: 0.7352 - val_loss: 0.4584 - val_accuracy: 0.8049\n",
            "Epoch 41/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.5770 - accuracy: 0.7169 - val_loss: 0.4875 - val_accuracy: 0.7561\n",
            "Epoch 42/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.5904 - accuracy: 0.7128 - val_loss: 0.4858 - val_accuracy: 0.7480\n",
            "Epoch 43/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.5281 - accuracy: 0.7515 - val_loss: 0.4389 - val_accuracy: 0.8455\n",
            "Epoch 44/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.5374 - accuracy: 0.7271 - val_loss: 0.5017 - val_accuracy: 0.7724\n",
            "Epoch 45/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.5416 - accuracy: 0.7251 - val_loss: 0.4673 - val_accuracy: 0.7967\n",
            "Epoch 46/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.5221 - accuracy: 0.7515 - val_loss: 0.4846 - val_accuracy: 0.7642\n",
            "Epoch 47/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.5630 - accuracy: 0.7251 - val_loss: 0.5134 - val_accuracy: 0.7561\n",
            "Epoch 48/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.5306 - accuracy: 0.7515 - val_loss: 0.4453 - val_accuracy: 0.8049\n",
            "Epoch 49/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.5368 - accuracy: 0.7413 - val_loss: 0.4859 - val_accuracy: 0.7724\n",
            "Epoch 50/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.5364 - accuracy: 0.7434 - val_loss: 0.4710 - val_accuracy: 0.7886\n",
            "Epoch 51/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.5414 - accuracy: 0.7128 - val_loss: 0.4491 - val_accuracy: 0.8293\n",
            "Epoch 52/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.5364 - accuracy: 0.7332 - val_loss: 0.5287 - val_accuracy: 0.7398\n",
            "Epoch 53/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.5294 - accuracy: 0.7556 - val_loss: 0.4532 - val_accuracy: 0.8211\n",
            "Epoch 54/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.5253 - accuracy: 0.7413 - val_loss: 0.4428 - val_accuracy: 0.8374\n",
            "Epoch 55/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.5321 - accuracy: 0.7169 - val_loss: 0.4410 - val_accuracy: 0.8130\n",
            "Epoch 56/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.5449 - accuracy: 0.7210 - val_loss: 0.5005 - val_accuracy: 0.7642\n",
            "Epoch 57/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.5352 - accuracy: 0.7556 - val_loss: 0.4369 - val_accuracy: 0.8537\n",
            "Epoch 58/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.5316 - accuracy: 0.7312 - val_loss: 0.4510 - val_accuracy: 0.8130\n",
            "Epoch 59/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.5311 - accuracy: 0.7373 - val_loss: 0.4323 - val_accuracy: 0.8293\n",
            "Epoch 60/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.5386 - accuracy: 0.7230 - val_loss: 0.4440 - val_accuracy: 0.8618\n",
            "Epoch 61/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.5278 - accuracy: 0.7291 - val_loss: 0.4322 - val_accuracy: 0.8537\n",
            "Epoch 62/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.5166 - accuracy: 0.7576 - val_loss: 0.4235 - val_accuracy: 0.8537\n",
            "Epoch 63/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.5485 - accuracy: 0.7393 - val_loss: 0.4509 - val_accuracy: 0.8618\n",
            "Epoch 64/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.5378 - accuracy: 0.7271 - val_loss: 0.4654 - val_accuracy: 0.7967\n",
            "Epoch 65/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.5447 - accuracy: 0.7352 - val_loss: 0.4567 - val_accuracy: 0.7967\n",
            "Epoch 66/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.5565 - accuracy: 0.7210 - val_loss: 0.4804 - val_accuracy: 0.8130\n",
            "Epoch 67/100\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.5256 - accuracy: 0.7393 - val_loss: 0.4441 - val_accuracy: 0.8293\n",
            "Epoch 68/100\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.5386 - accuracy: 0.7312 - val_loss: 0.4654 - val_accuracy: 0.8293\n",
            "Epoch 69/100\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.5413 - accuracy: 0.7352 - val_loss: 0.4681 - val_accuracy: 0.7886\n",
            "Epoch 70/100\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.5520 - accuracy: 0.7312 - val_loss: 0.4428 - val_accuracy: 0.8455\n",
            "Epoch 71/100\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.5394 - accuracy: 0.7536 - val_loss: 0.4391 - val_accuracy: 0.8455\n",
            "Epoch 72/100\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.5493 - accuracy: 0.7271 - val_loss: 0.4495 - val_accuracy: 0.8374\n",
            "Epoch 73/100\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.5448 - accuracy: 0.7393 - val_loss: 0.4517 - val_accuracy: 0.8211\n",
            "Epoch 74/100\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.5599 - accuracy: 0.7251 - val_loss: 0.4551 - val_accuracy: 0.8537\n",
            "Epoch 75/100\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.5311 - accuracy: 0.7434 - val_loss: 0.4464 - val_accuracy: 0.8293\n",
            "Epoch 76/100\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.5388 - accuracy: 0.7271 - val_loss: 0.4821 - val_accuracy: 0.7642\n",
            "Epoch 77/100\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.5352 - accuracy: 0.7332 - val_loss: 0.4303 - val_accuracy: 0.8618\n",
            "Epoch 78/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.5372 - accuracy: 0.7373 - val_loss: 0.4554 - val_accuracy: 0.8049\n",
            "Epoch 79/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.5860 - accuracy: 0.6986 - val_loss: 0.4740 - val_accuracy: 0.8618\n",
            "Epoch 80/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.5377 - accuracy: 0.7312 - val_loss: 0.4512 - val_accuracy: 0.8293\n",
            "Epoch 81/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.5297 - accuracy: 0.7332 - val_loss: 0.4419 - val_accuracy: 0.8293\n",
            "Epoch 82/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.5218 - accuracy: 0.7454 - val_loss: 0.4338 - val_accuracy: 0.8293\n",
            "Epoch 83/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.5629 - accuracy: 0.7230 - val_loss: 0.4549 - val_accuracy: 0.8211\n",
            "Epoch 84/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.5235 - accuracy: 0.7413 - val_loss: 0.4500 - val_accuracy: 0.8049\n",
            "Epoch 85/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.5195 - accuracy: 0.7597 - val_loss: 0.4349 - val_accuracy: 0.8374\n",
            "Epoch 86/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.5348 - accuracy: 0.7495 - val_loss: 0.5443 - val_accuracy: 0.7154\n",
            "Epoch 87/100\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.5296 - accuracy: 0.7393 - val_loss: 0.4428 - val_accuracy: 0.8130\n",
            "Epoch 88/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.5176 - accuracy: 0.7536 - val_loss: 0.4227 - val_accuracy: 0.8618\n",
            "Epoch 89/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.5230 - accuracy: 0.7515 - val_loss: 0.4422 - val_accuracy: 0.8211\n",
            "Epoch 90/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.5257 - accuracy: 0.7536 - val_loss: 0.4291 - val_accuracy: 0.8618\n",
            "Epoch 91/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.5375 - accuracy: 0.7454 - val_loss: 0.4494 - val_accuracy: 0.8211\n",
            "Epoch 92/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.5315 - accuracy: 0.7312 - val_loss: 0.4255 - val_accuracy: 0.8699\n",
            "Epoch 93/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.5337 - accuracy: 0.7373 - val_loss: 0.4374 - val_accuracy: 0.8293\n",
            "Epoch 94/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.5221 - accuracy: 0.7617 - val_loss: 0.4517 - val_accuracy: 0.8049\n",
            "Epoch 95/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.5259 - accuracy: 0.7413 - val_loss: 0.4836 - val_accuracy: 0.7642\n",
            "Epoch 96/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.5448 - accuracy: 0.7251 - val_loss: 0.4339 - val_accuracy: 0.8618\n",
            "Epoch 97/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.5199 - accuracy: 0.7678 - val_loss: 0.4571 - val_accuracy: 0.7967\n",
            "Epoch 98/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.5374 - accuracy: 0.7556 - val_loss: 0.4930 - val_accuracy: 0.7073\n",
            "Epoch 99/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.5302 - accuracy: 0.7332 - val_loss: 0.4745 - val_accuracy: 0.7886\n",
            "Epoch 100/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.5266 - accuracy: 0.7413 - val_loss: 0.4333 - val_accuracy: 0.8537\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7ff69cd104f0>"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_model.save(\"best_model_super.h5\")"
      ],
      "metadata": {
        "id": "VLlQM-4TqyIw"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "modelOriginal = load_model(\"model.h5\")\n",
        "modelHp = load_model(\"best_model_hp.h5\")\n",
        "modelRe = load_model(\"best_model_regularization.h5\")\n",
        "modelOp = load_model(\"best_model_optimization.h5\")\n",
        "modelSuper = load_model(\"best_model_super.h5\")\n",
        "\n",
        "lossOriginal, accuracyOriginal = modelOriginal.evaluate(X_test, y_test)\n",
        "lossHp, accuracyHp = modelHp.evaluate(X_test, y_test)\n",
        "lossRe, accuracyRe = modelRe.evaluate(X_test, y_test)\n",
        "lossOp, accuracyOp = modelOp.evaluate(X_test, y_test)\n",
        "lossSuper, accuracySuper = modelSuper.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9deVfOnns3fT",
        "outputId": "a1936bc0-f2e5-4058-c842-ca8bed1eb0e6"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
            "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6241 - accuracy: 0.6753\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6079 - accuracy: 0.7208\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6683 - accuracy: 0.7468\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6644 - accuracy: 0.7468\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5448 - accuracy: 0.7403\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create the DataFrame\n",
        "df = pd.DataFrame({'': ['Original','Hyperparameter Tuning (Keras Tuner)','Regularization (L2 Regularization)','Optimization (Adam -> RMSprop)','Combined 3 ways'],\n",
        "                   'Loss': [lossOriginal, lossHp, lossRe, lossOp, lossSuper],\n",
        "                   'Accuracy': [accuracyOriginal, accuracyHp, accuracyRe, accuracyOp, accuracySuper]})\n",
        "\n",
        "# print the table using tabulate\n",
        "print(tabulate(df, headers='keys', tablefmt='pipe', floatfmt='.4f'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6t453wmXwTf0",
        "outputId": "6e922cd0-0bc6-499d-caa3-40292cb4450c"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "|    |                                     |   Loss |   Accuracy |\n",
            "|---:|:------------------------------------|-------:|-----------:|\n",
            "|  0 | Original                            | 0.6241 |     0.6753 |\n",
            "|  1 | Hyperparameter Tuning (Keras Tuner) | 0.6079 |     0.7208 |\n",
            "|  2 | Regularization (L2 Regularization)  | 0.6683 |     0.7468 |\n",
            "|  3 | Optimization (Adam -> RMSprop)      | 0.6644 |     0.7468 |\n",
            "|  4 | Combined 3 ways                     | 0.5448 |     0.7403 |\n"
          ]
        }
      ]
    }
  ]
}