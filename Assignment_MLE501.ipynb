{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNtAuAxqhhbX1DWg3OuhkEt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/minhhieu9800/MLE501/blob/main/Assignment_MLE501.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction\n",
        "\n",
        "Name: Nguyễn Minh Hiếu </br>\n",
        "Main Class: MSE#11HCM </br>\n",
        "Student ID: 22MSE23062 </br>\n",
        "Email: hieu22mse23062@fsb.edu.vn"
      ],
      "metadata": {
        "id": "AaecXjCquLAG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Assignment"
      ],
      "metadata": {
        "id": "hYaKemdZvyGv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from tabulate import tabulate\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.models import load_model\n",
        "from keras.optimizers import Adam, RMSprop\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "F15QZDthv7nc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load data"
      ],
      "metadata": {
        "id": "u0RGH5Du5V9h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# https://www.kaggle.com/datasets/mathchi/diabetes-data-set\n",
        "url = 'https://minhhieu9800.github.io/MLE501/diabetes.csv'\n",
        "df = pd.read_csv(url)"
      ],
      "metadata": {
        "id": "EbTZStr3yU1C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = df.drop(['Outcome'], axis=1)\n",
        "y = df['Outcome']\n",
        "\n",
        "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.2)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.2)"
      ],
      "metadata": {
        "id": "eTXALQYuyb26"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Build model"
      ],
      "metadata": {
        "id": "70D9DjkU5TJj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(8, input_dim=8, activation='relu'))\n",
        "model.add(Dense(8, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.summary()\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.fit(X_train, y_train, epochs=100, batch_size=8, validation_data=(X_val, y_val))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "maH048DE55yx",
        "outputId": "6c9d3398-6aeb-4127-f82f-602b277efe5e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 8)                 72        \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 8)                 72        \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1)                 9         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 153\n",
            "Trainable params: 153\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "62/62 [==============================] - 6s 7ms/step - loss: 3.9320 - accuracy: 0.5112 - val_loss: 2.2983 - val_accuracy: 0.5854\n",
            "Epoch 2/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 2.8068 - accuracy: 0.5458 - val_loss: 1.8198 - val_accuracy: 0.5691\n",
            "Epoch 3/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 2.3057 - accuracy: 0.5601 - val_loss: 1.6438 - val_accuracy: 0.5772\n",
            "Epoch 4/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 2.0239 - accuracy: 0.5723 - val_loss: 1.5369 - val_accuracy: 0.5691\n",
            "Epoch 5/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 1.7565 - accuracy: 0.5662 - val_loss: 1.4702 - val_accuracy: 0.6992\n",
            "Epoch 6/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 1.5684 - accuracy: 0.5906 - val_loss: 1.6545 - val_accuracy: 0.5122\n",
            "Epoch 7/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 1.4147 - accuracy: 0.6293 - val_loss: 1.1458 - val_accuracy: 0.6667\n",
            "Epoch 8/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 1.3347 - accuracy: 0.6008 - val_loss: 1.0515 - val_accuracy: 0.7073\n",
            "Epoch 9/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 1.2365 - accuracy: 0.6273 - val_loss: 1.0284 - val_accuracy: 0.6992\n",
            "Epoch 10/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 1.2483 - accuracy: 0.6354 - val_loss: 1.0012 - val_accuracy: 0.6585\n",
            "Epoch 11/100\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 1.1323 - accuracy: 0.6334 - val_loss: 0.9028 - val_accuracy: 0.6911\n",
            "Epoch 12/100\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 1.1025 - accuracy: 0.6517 - val_loss: 0.8544 - val_accuracy: 0.6992\n",
            "Epoch 13/100\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 1.0268 - accuracy: 0.6314 - val_loss: 0.8234 - val_accuracy: 0.6911\n",
            "Epoch 14/100\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.9414 - accuracy: 0.6680 - val_loss: 0.9109 - val_accuracy: 0.6341\n",
            "Epoch 15/100\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.9420 - accuracy: 0.6619 - val_loss: 0.7475 - val_accuracy: 0.7236\n",
            "Epoch 16/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.8809 - accuracy: 0.6578 - val_loss: 0.7565 - val_accuracy: 0.6911\n",
            "Epoch 17/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.8440 - accuracy: 0.6517 - val_loss: 0.7097 - val_accuracy: 0.6829\n",
            "Epoch 18/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.7440 - accuracy: 0.6823 - val_loss: 0.6918 - val_accuracy: 0.7073\n",
            "Epoch 19/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.7563 - accuracy: 0.6904 - val_loss: 0.7624 - val_accuracy: 0.6179\n",
            "Epoch 20/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.7375 - accuracy: 0.6884 - val_loss: 0.6405 - val_accuracy: 0.6911\n",
            "Epoch 21/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.6870 - accuracy: 0.6823 - val_loss: 0.6341 - val_accuracy: 0.6992\n",
            "Epoch 22/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.6746 - accuracy: 0.7026 - val_loss: 0.6860 - val_accuracy: 0.6098\n",
            "Epoch 23/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.7034 - accuracy: 0.6660 - val_loss: 0.5923 - val_accuracy: 0.6911\n",
            "Epoch 24/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.6528 - accuracy: 0.7210 - val_loss: 0.6795 - val_accuracy: 0.6341\n",
            "Epoch 25/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.6316 - accuracy: 0.6986 - val_loss: 0.6250 - val_accuracy: 0.6829\n",
            "Epoch 26/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.6524 - accuracy: 0.6904 - val_loss: 0.6350 - val_accuracy: 0.7073\n",
            "Epoch 27/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.6907 - accuracy: 0.7067 - val_loss: 0.6223 - val_accuracy: 0.6992\n",
            "Epoch 28/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.6155 - accuracy: 0.6925 - val_loss: 0.5892 - val_accuracy: 0.6992\n",
            "Epoch 29/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.6076 - accuracy: 0.7088 - val_loss: 0.5597 - val_accuracy: 0.7398\n",
            "Epoch 30/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.6107 - accuracy: 0.7189 - val_loss: 0.5736 - val_accuracy: 0.7398\n",
            "Epoch 31/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.6131 - accuracy: 0.7312 - val_loss: 0.6542 - val_accuracy: 0.6341\n",
            "Epoch 32/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.6940 - accuracy: 0.6558 - val_loss: 0.6106 - val_accuracy: 0.7073\n",
            "Epoch 33/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.6314 - accuracy: 0.6843 - val_loss: 0.6091 - val_accuracy: 0.6992\n",
            "Epoch 34/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.6434 - accuracy: 0.6925 - val_loss: 0.5573 - val_accuracy: 0.7073\n",
            "Epoch 35/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.5737 - accuracy: 0.7169 - val_loss: 0.6088 - val_accuracy: 0.6829\n",
            "Epoch 36/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.6025 - accuracy: 0.6986 - val_loss: 0.5787 - val_accuracy: 0.7154\n",
            "Epoch 37/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.6147 - accuracy: 0.7047 - val_loss: 0.5776 - val_accuracy: 0.7154\n",
            "Epoch 38/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.5708 - accuracy: 0.7108 - val_loss: 0.5883 - val_accuracy: 0.7236\n",
            "Epoch 39/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.6210 - accuracy: 0.7067 - val_loss: 0.5765 - val_accuracy: 0.7073\n",
            "Epoch 40/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.5605 - accuracy: 0.6925 - val_loss: 0.5608 - val_accuracy: 0.7073\n",
            "Epoch 41/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.5548 - accuracy: 0.7067 - val_loss: 0.6031 - val_accuracy: 0.6992\n",
            "Epoch 42/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.5964 - accuracy: 0.7067 - val_loss: 0.5748 - val_accuracy: 0.6992\n",
            "Epoch 43/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.5848 - accuracy: 0.7006 - val_loss: 0.5925 - val_accuracy: 0.7317\n",
            "Epoch 44/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.5669 - accuracy: 0.7108 - val_loss: 0.6013 - val_accuracy: 0.7317\n",
            "Epoch 45/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.5664 - accuracy: 0.7210 - val_loss: 0.5678 - val_accuracy: 0.7317\n",
            "Epoch 46/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.5464 - accuracy: 0.7332 - val_loss: 0.7012 - val_accuracy: 0.7073\n",
            "Epoch 47/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.5926 - accuracy: 0.7169 - val_loss: 0.5883 - val_accuracy: 0.7154\n",
            "Epoch 48/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.5687 - accuracy: 0.7047 - val_loss: 0.5837 - val_accuracy: 0.6992\n",
            "Epoch 49/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.5664 - accuracy: 0.7189 - val_loss: 0.6351 - val_accuracy: 0.7317\n",
            "Epoch 50/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.5674 - accuracy: 0.7169 - val_loss: 0.5440 - val_accuracy: 0.7073\n",
            "Epoch 51/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.5675 - accuracy: 0.7169 - val_loss: 0.5724 - val_accuracy: 0.7154\n",
            "Epoch 52/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.5552 - accuracy: 0.7271 - val_loss: 0.5468 - val_accuracy: 0.7154\n",
            "Epoch 53/100\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.6023 - accuracy: 0.6965 - val_loss: 0.8177 - val_accuracy: 0.5610\n",
            "Epoch 54/100\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.5747 - accuracy: 0.7088 - val_loss: 0.5763 - val_accuracy: 0.6992\n",
            "Epoch 55/100\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.5729 - accuracy: 0.7088 - val_loss: 0.5612 - val_accuracy: 0.7398\n",
            "Epoch 56/100\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.5395 - accuracy: 0.7251 - val_loss: 0.5484 - val_accuracy: 0.7398\n",
            "Epoch 57/100\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.5630 - accuracy: 0.7251 - val_loss: 0.6750 - val_accuracy: 0.7236\n",
            "Epoch 58/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.6230 - accuracy: 0.7026 - val_loss: 0.6192 - val_accuracy: 0.7073\n",
            "Epoch 59/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.5886 - accuracy: 0.6904 - val_loss: 0.5394 - val_accuracy: 0.7480\n",
            "Epoch 60/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.5636 - accuracy: 0.7210 - val_loss: 0.6539 - val_accuracy: 0.6911\n",
            "Epoch 61/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.5566 - accuracy: 0.7312 - val_loss: 0.5744 - val_accuracy: 0.7398\n",
            "Epoch 62/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.5750 - accuracy: 0.7088 - val_loss: 0.6779 - val_accuracy: 0.6504\n",
            "Epoch 63/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.5687 - accuracy: 0.7189 - val_loss: 0.6136 - val_accuracy: 0.7236\n",
            "Epoch 64/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.5582 - accuracy: 0.7169 - val_loss: 0.5449 - val_accuracy: 0.7317\n",
            "Epoch 65/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.5490 - accuracy: 0.7312 - val_loss: 0.7111 - val_accuracy: 0.6992\n",
            "Epoch 66/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.5634 - accuracy: 0.7251 - val_loss: 0.5987 - val_accuracy: 0.6992\n",
            "Epoch 67/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.5651 - accuracy: 0.7169 - val_loss: 0.5676 - val_accuracy: 0.7317\n",
            "Epoch 68/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.5985 - accuracy: 0.7189 - val_loss: 0.5996 - val_accuracy: 0.7317\n",
            "Epoch 69/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.5502 - accuracy: 0.7251 - val_loss: 0.5416 - val_accuracy: 0.7317\n",
            "Epoch 70/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.5569 - accuracy: 0.7312 - val_loss: 0.5405 - val_accuracy: 0.7317\n",
            "Epoch 71/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.5438 - accuracy: 0.7088 - val_loss: 0.5226 - val_accuracy: 0.7317\n",
            "Epoch 72/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.5347 - accuracy: 0.7312 - val_loss: 0.5392 - val_accuracy: 0.7236\n",
            "Epoch 73/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.5433 - accuracy: 0.7251 - val_loss: 0.5884 - val_accuracy: 0.7480\n",
            "Epoch 74/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.5381 - accuracy: 0.7291 - val_loss: 0.5899 - val_accuracy: 0.7236\n",
            "Epoch 75/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.6190 - accuracy: 0.7088 - val_loss: 0.5255 - val_accuracy: 0.7317\n",
            "Epoch 76/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.6065 - accuracy: 0.7210 - val_loss: 0.5492 - val_accuracy: 0.7236\n",
            "Epoch 77/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.5601 - accuracy: 0.7189 - val_loss: 0.5381 - val_accuracy: 0.7480\n",
            "Epoch 78/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.5466 - accuracy: 0.7434 - val_loss: 0.5197 - val_accuracy: 0.7398\n",
            "Epoch 79/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.5605 - accuracy: 0.7047 - val_loss: 0.5678 - val_accuracy: 0.7398\n",
            "Epoch 80/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.5324 - accuracy: 0.7271 - val_loss: 0.5372 - val_accuracy: 0.7317\n",
            "Epoch 81/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.5380 - accuracy: 0.7413 - val_loss: 0.5218 - val_accuracy: 0.7317\n",
            "Epoch 82/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.5428 - accuracy: 0.7251 - val_loss: 0.6156 - val_accuracy: 0.6992\n",
            "Epoch 83/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.5626 - accuracy: 0.7413 - val_loss: 0.5661 - val_accuracy: 0.7561\n",
            "Epoch 84/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.6220 - accuracy: 0.7047 - val_loss: 0.5270 - val_accuracy: 0.7317\n",
            "Epoch 85/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.6413 - accuracy: 0.6925 - val_loss: 0.5396 - val_accuracy: 0.7398\n",
            "Epoch 86/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.5298 - accuracy: 0.7230 - val_loss: 0.5939 - val_accuracy: 0.7154\n",
            "Epoch 87/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.5272 - accuracy: 0.7434 - val_loss: 0.5262 - val_accuracy: 0.7317\n",
            "Epoch 88/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.5670 - accuracy: 0.7210 - val_loss: 0.5215 - val_accuracy: 0.7236\n",
            "Epoch 89/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.5654 - accuracy: 0.7189 - val_loss: 0.5276 - val_accuracy: 0.7398\n",
            "Epoch 90/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.5304 - accuracy: 0.7251 - val_loss: 0.5338 - val_accuracy: 0.7398\n",
            "Epoch 91/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.5408 - accuracy: 0.7210 - val_loss: 0.5349 - val_accuracy: 0.7480\n",
            "Epoch 92/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.5827 - accuracy: 0.6843 - val_loss: 0.5395 - val_accuracy: 0.7724\n",
            "Epoch 93/100\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.5552 - accuracy: 0.7128 - val_loss: 0.5301 - val_accuracy: 0.7561\n",
            "Epoch 94/100\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.5987 - accuracy: 0.6986 - val_loss: 0.6923 - val_accuracy: 0.6585\n",
            "Epoch 95/100\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.5767 - accuracy: 0.7393 - val_loss: 0.5000 - val_accuracy: 0.7317\n",
            "Epoch 96/100\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.5261 - accuracy: 0.7352 - val_loss: 0.5817 - val_accuracy: 0.7480\n",
            "Epoch 97/100\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.5265 - accuracy: 0.7393 - val_loss: 0.5059 - val_accuracy: 0.7317\n",
            "Epoch 98/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.5398 - accuracy: 0.7373 - val_loss: 0.5256 - val_accuracy: 0.7561\n",
            "Epoch 99/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.5292 - accuracy: 0.7393 - val_loss: 0.6465 - val_accuracy: 0.7236\n",
            "Epoch 100/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.5568 - accuracy: 0.7393 - val_loss: 0.5035 - val_accuracy: 0.7317\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f006003e580>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"model.h5\")"
      ],
      "metadata": {
        "id": "6hEeFRlL6o44"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = load_model(\"model.h5\")"
      ],
      "metadata": {
        "id": "M0Q_XLUU-o3A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(\"Loss: \", loss)\n",
        "print(\"Accuracy: \", accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uSMZ-Tb__Xtf",
        "outputId": "94c342b1-057e-41ef-9e44-603d0b2a4e1a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6000 - accuracy: 0.7078\n",
            "Loss:  0.5999835729598999\n",
            "Accuracy:  0.7077922224998474\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Improving model by Hyperparameter Tuning (Keras Tuner)"
      ],
      "metadata": {
        "id": "grEAzn7nZVp_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install keras-tuner\n",
        "import keras_tuner as kt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "npqDTQMsUpLh",
        "outputId": "f59752e8-0ad3-4b0c-bc63-178c2e9cfc0f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting keras-tuner\n",
            "  Downloading keras_tuner-1.3.0-py3-none-any.whl (167 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.3/167.3 KB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from keras-tuner) (2.25.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from keras-tuner) (23.0)\n",
            "Collecting kt-legacy\n",
            "  Downloading kt_legacy-1.0.4-py3-none-any.whl (9.6 kB)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.8/dist-packages (from keras-tuner) (7.9.0)\n",
            "Requirement already satisfied: tensorflow>=2.0 in /usr/local/lib/python3.8/dist-packages (from keras-tuner) (2.11.0)\n",
            "Requirement already satisfied: keras<2.12,>=2.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0->keras-tuner) (2.11.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0->keras-tuner) (4.5.0)\n",
            "Requirement already satisfied: tensorboard<2.12,>=2.11 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0->keras-tuner) (2.11.2)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0->keras-tuner) (23.1.21)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0->keras-tuner) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0->keras-tuner) (1.6.3)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0->keras-tuner) (3.19.6)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0->keras-tuner) (3.1.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0->keras-tuner) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0->keras-tuner) (15.0.6.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0->keras-tuner) (3.3.0)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0->keras-tuner) (1.22.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0->keras-tuner) (57.4.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.12,>=2.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0->keras-tuner) (2.11.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0->keras-tuner) (2.2.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0->keras-tuner) (1.15.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0->keras-tuner) (1.51.3)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0->keras-tuner) (0.4.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0->keras-tuner) (0.31.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0->keras-tuner) (1.15.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.8/dist-packages (from ipython->keras-tuner) (0.2.0)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.8/dist-packages (from ipython->keras-tuner) (0.7.5)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.8/dist-packages (from ipython->keras-tuner) (2.6.1)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.8/dist-packages (from ipython->keras-tuner) (5.7.1)\n",
            "Collecting jedi>=0.10\n",
            "  Downloading jedi-0.18.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m58.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: prompt-toolkit<2.1.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from ipython->keras-tuner) (2.0.10)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.8/dist-packages (from ipython->keras-tuner) (4.8.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.8/dist-packages (from ipython->keras-tuner) (4.4.2)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->keras-tuner) (1.26.14)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->keras-tuner) (2.10)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->keras-tuner) (4.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->keras-tuner) (2022.12.7)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.8/dist-packages (from astunparse>=1.6.0->tensorflow>=2.0->keras-tuner) (0.38.4)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.8/dist-packages (from jedi>=0.10->ipython->keras-tuner) (0.8.3)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.8/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython->keras-tuner) (0.2.6)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow>=2.0->keras-tuner) (2.16.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow>=2.0->keras-tuner) (2.2.3)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow>=2.0->keras-tuner) (0.6.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow>=2.0->keras-tuner) (1.8.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow>=2.0->keras-tuner) (0.4.6)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow>=2.0->keras-tuner) (3.4.1)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.8/dist-packages (from pexpect->ipython->keras-tuner) (0.7.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow>=2.0->keras-tuner) (4.9)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow>=2.0->keras-tuner) (5.3.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow>=2.0->keras-tuner) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow>=2.0->keras-tuner) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.8/dist-packages (from markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow>=2.0->keras-tuner) (6.0.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.8/dist-packages (from werkzeug>=1.0.1->tensorboard<2.12,>=2.11->tensorflow>=2.0->keras-tuner) (2.1.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow>=2.0->keras-tuner) (3.15.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow>=2.0->keras-tuner) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow>=2.0->keras-tuner) (3.2.2)\n",
            "Installing collected packages: kt-legacy, jedi, keras-tuner\n",
            "Successfully installed jedi-0.18.2 keras-tuner-1.3.0 kt-legacy-1.0.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create function: build Hyper model\n",
        "def build_model(hp): \n",
        "  model = keras.Sequential()\n",
        "\n",
        "  X = hp.Int('units_input', min_value=8, max_value=64, step=8)\n",
        "  model.add(Dense(units=X, input_dim=8, activation='relu'))\n",
        "\n",
        "  for i in range(hp.Int('num_layers', 1, 4)):\n",
        "    Y = hp.Int('units_' + str(i), min_value=8, max_value=64, step=8)\n",
        "    model.add(Dense(units=Y, activation='relu'))\n",
        "\n",
        "  model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "  lr = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
        "  model.compile(\n",
        "        optimizer=Adam(learning_rate=lr),\n",
        "        loss='binary_crossentropy',\n",
        "        metrics=['accuracy'])\n",
        "  \n",
        "  return model"
      ],
      "metadata": {
        "id": "TZZiAkkUOb81"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create Tuner\n",
        "tuner = kt.Hyperband (build_model, objective=\"val_accuracy\", directory=\"tuner_dir_1\", project_name=\"MLE501_Tuner_1\")"
      ],
      "metadata": {
        "id": "_jzNzE7NT-5O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tuner.search(X_train, y_train, epochs=10, validation_data=(X_val, y_val))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O_njRkaEWHo6",
        "outputId": "8be0d2d6-aab2-4555-baa5-77a614f7cd5e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 254 Complete [00h 00m 21s]\n",
            "val_accuracy: 0.707317054271698\n",
            "\n",
            "Best val_accuracy So Far: 0.8130081295967102\n",
            "Total elapsed time: 00h 12m 55s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get best model\n",
        "best_model = tuner.get_best_models(num_models=1)[0]\n",
        "\n",
        "best_model.summary()\n",
        "\n",
        "best_model.fit(X_train, y_train, epochs=100, batch_size=8, validation_data=(X_val, y_val))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yYYXWVBTZSA9",
        "outputId": "473f4b83-8416-4f88-b9c6-521f03f20afe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 8)                 72        \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 24)                216       \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 24)                600       \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 25        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 913\n",
            "Trainable params: 913\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "62/62 [==============================] - 1s 8ms/step - loss: 0.6414 - accuracy: 0.7067 - val_loss: 0.5256 - val_accuracy: 0.7317\n",
            "Epoch 2/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.5704 - accuracy: 0.7169 - val_loss: 0.5156 - val_accuracy: 0.7724\n",
            "Epoch 3/100\n",
            "62/62 [==============================] - 0s 8ms/step - loss: 0.5614 - accuracy: 0.7271 - val_loss: 0.5508 - val_accuracy: 0.7480\n",
            "Epoch 4/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.5725 - accuracy: 0.7169 - val_loss: 0.4924 - val_accuracy: 0.7480\n",
            "Epoch 5/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.5527 - accuracy: 0.7434 - val_loss: 0.4933 - val_accuracy: 0.7805\n",
            "Epoch 6/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.5788 - accuracy: 0.7067 - val_loss: 0.6404 - val_accuracy: 0.6911\n",
            "Epoch 7/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.5412 - accuracy: 0.7291 - val_loss: 0.4929 - val_accuracy: 0.7561\n",
            "Epoch 8/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.5266 - accuracy: 0.7291 - val_loss: 0.4795 - val_accuracy: 0.8293\n",
            "Epoch 9/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.5402 - accuracy: 0.7434 - val_loss: 0.4745 - val_accuracy: 0.7886\n",
            "Epoch 10/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.5279 - accuracy: 0.7149 - val_loss: 0.4762 - val_accuracy: 0.7561\n",
            "Epoch 11/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.5355 - accuracy: 0.7332 - val_loss: 0.4705 - val_accuracy: 0.8049\n",
            "Epoch 12/100\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.5242 - accuracy: 0.7393 - val_loss: 0.5047 - val_accuracy: 0.7480\n",
            "Epoch 13/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.5174 - accuracy: 0.7495 - val_loss: 0.4997 - val_accuracy: 0.7561\n",
            "Epoch 14/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.5449 - accuracy: 0.7373 - val_loss: 0.5064 - val_accuracy: 0.7480\n",
            "Epoch 15/100\n",
            "62/62 [==============================] - 0s 8ms/step - loss: 0.5358 - accuracy: 0.7291 - val_loss: 0.5319 - val_accuracy: 0.7317\n",
            "Epoch 16/100\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.5302 - accuracy: 0.7251 - val_loss: 0.4985 - val_accuracy: 0.7886\n",
            "Epoch 17/100\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.5348 - accuracy: 0.7536 - val_loss: 0.4798 - val_accuracy: 0.7561\n",
            "Epoch 18/100\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.5070 - accuracy: 0.7434 - val_loss: 0.4688 - val_accuracy: 0.7967\n",
            "Epoch 19/100\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.5098 - accuracy: 0.7434 - val_loss: 0.4718 - val_accuracy: 0.7480\n",
            "Epoch 20/100\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.5475 - accuracy: 0.7373 - val_loss: 0.4745 - val_accuracy: 0.7805\n",
            "Epoch 21/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.5216 - accuracy: 0.7536 - val_loss: 0.4864 - val_accuracy: 0.8049\n",
            "Epoch 22/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.5181 - accuracy: 0.7332 - val_loss: 0.5157 - val_accuracy: 0.7398\n",
            "Epoch 23/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.5031 - accuracy: 0.7617 - val_loss: 0.5219 - val_accuracy: 0.7154\n",
            "Epoch 24/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.5349 - accuracy: 0.7413 - val_loss: 0.4939 - val_accuracy: 0.7724\n",
            "Epoch 25/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.5186 - accuracy: 0.7515 - val_loss: 0.5335 - val_accuracy: 0.7480\n",
            "Epoch 26/100\n",
            "62/62 [==============================] - 1s 8ms/step - loss: 0.5229 - accuracy: 0.7312 - val_loss: 0.4815 - val_accuracy: 0.7886\n",
            "Epoch 27/100\n",
            "62/62 [==============================] - 0s 8ms/step - loss: 0.5212 - accuracy: 0.7515 - val_loss: 0.4868 - val_accuracy: 0.7642\n",
            "Epoch 28/100\n",
            "62/62 [==============================] - 0s 8ms/step - loss: 0.5055 - accuracy: 0.7413 - val_loss: 0.5228 - val_accuracy: 0.7317\n",
            "Epoch 29/100\n",
            "62/62 [==============================] - 0s 8ms/step - loss: 0.5303 - accuracy: 0.7434 - val_loss: 0.4995 - val_accuracy: 0.7480\n",
            "Epoch 30/100\n",
            "62/62 [==============================] - 0s 8ms/step - loss: 0.5410 - accuracy: 0.7251 - val_loss: 0.4676 - val_accuracy: 0.8049\n",
            "Epoch 31/100\n",
            "62/62 [==============================] - 1s 8ms/step - loss: 0.5143 - accuracy: 0.7536 - val_loss: 0.6133 - val_accuracy: 0.6667\n",
            "Epoch 32/100\n",
            "62/62 [==============================] - 0s 8ms/step - loss: 0.5555 - accuracy: 0.7332 - val_loss: 0.4994 - val_accuracy: 0.7154\n",
            "Epoch 33/100\n",
            "62/62 [==============================] - 1s 9ms/step - loss: 0.5189 - accuracy: 0.7434 - val_loss: 0.4948 - val_accuracy: 0.7724\n",
            "Epoch 34/100\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.5266 - accuracy: 0.7413 - val_loss: 0.4796 - val_accuracy: 0.7805\n",
            "Epoch 35/100\n",
            "62/62 [==============================] - 1s 9ms/step - loss: 0.5232 - accuracy: 0.7291 - val_loss: 0.4604 - val_accuracy: 0.8049\n",
            "Epoch 36/100\n",
            "62/62 [==============================] - 1s 8ms/step - loss: 0.5034 - accuracy: 0.7576 - val_loss: 0.4779 - val_accuracy: 0.7967\n",
            "Epoch 37/100\n",
            "62/62 [==============================] - 0s 8ms/step - loss: 0.4873 - accuracy: 0.7536 - val_loss: 0.6710 - val_accuracy: 0.6504\n",
            "Epoch 38/100\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.5513 - accuracy: 0.7332 - val_loss: 0.4845 - val_accuracy: 0.7886\n",
            "Epoch 39/100\n",
            "62/62 [==============================] - 0s 8ms/step - loss: 0.4993 - accuracy: 0.7678 - val_loss: 0.4922 - val_accuracy: 0.7398\n",
            "Epoch 40/100\n",
            "62/62 [==============================] - 1s 8ms/step - loss: 0.4867 - accuracy: 0.7760 - val_loss: 0.4849 - val_accuracy: 0.7642\n",
            "Epoch 41/100\n",
            "62/62 [==============================] - 1s 10ms/step - loss: 0.5066 - accuracy: 0.7637 - val_loss: 0.5024 - val_accuracy: 0.7642\n",
            "Epoch 42/100\n",
            "62/62 [==============================] - 1s 10ms/step - loss: 0.5103 - accuracy: 0.7454 - val_loss: 0.5671 - val_accuracy: 0.7317\n",
            "Epoch 43/100\n",
            "62/62 [==============================] - 1s 13ms/step - loss: 0.5142 - accuracy: 0.7434 - val_loss: 0.4822 - val_accuracy: 0.7967\n",
            "Epoch 44/100\n",
            "62/62 [==============================] - 1s 17ms/step - loss: 0.5326 - accuracy: 0.7434 - val_loss: 0.4584 - val_accuracy: 0.7886\n",
            "Epoch 45/100\n",
            "62/62 [==============================] - 1s 12ms/step - loss: 0.4962 - accuracy: 0.7576 - val_loss: 0.4598 - val_accuracy: 0.7967\n",
            "Epoch 46/100\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.5045 - accuracy: 0.7495 - val_loss: 0.5593 - val_accuracy: 0.7398\n",
            "Epoch 47/100\n",
            "62/62 [==============================] - 1s 9ms/step - loss: 0.5040 - accuracy: 0.7515 - val_loss: 0.5118 - val_accuracy: 0.7642\n",
            "Epoch 48/100\n",
            "62/62 [==============================] - 1s 8ms/step - loss: 0.4885 - accuracy: 0.7760 - val_loss: 0.4695 - val_accuracy: 0.7805\n",
            "Epoch 49/100\n",
            "62/62 [==============================] - 1s 10ms/step - loss: 0.4963 - accuracy: 0.7780 - val_loss: 0.5351 - val_accuracy: 0.7317\n",
            "Epoch 50/100\n",
            "62/62 [==============================] - 1s 10ms/step - loss: 0.4911 - accuracy: 0.7637 - val_loss: 0.5194 - val_accuracy: 0.7561\n",
            "Epoch 51/100\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.5147 - accuracy: 0.7413 - val_loss: 0.5090 - val_accuracy: 0.7642\n",
            "Epoch 52/100\n",
            "62/62 [==============================] - 1s 9ms/step - loss: 0.5032 - accuracy: 0.7617 - val_loss: 0.5828 - val_accuracy: 0.7154\n",
            "Epoch 53/100\n",
            "62/62 [==============================] - 1s 8ms/step - loss: 0.5312 - accuracy: 0.7332 - val_loss: 0.4798 - val_accuracy: 0.7561\n",
            "Epoch 54/100\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.5127 - accuracy: 0.7373 - val_loss: 0.4629 - val_accuracy: 0.8130\n",
            "Epoch 55/100\n",
            "62/62 [==============================] - 1s 12ms/step - loss: 0.5428 - accuracy: 0.7495 - val_loss: 0.4819 - val_accuracy: 0.7967\n",
            "Epoch 56/100\n",
            "62/62 [==============================] - 1s 9ms/step - loss: 0.5209 - accuracy: 0.7251 - val_loss: 0.5082 - val_accuracy: 0.7561\n",
            "Epoch 57/100\n",
            "62/62 [==============================] - 1s 10ms/step - loss: 0.4978 - accuracy: 0.7658 - val_loss: 0.4837 - val_accuracy: 0.7805\n",
            "Epoch 58/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.4910 - accuracy: 0.7658 - val_loss: 0.5084 - val_accuracy: 0.7724\n",
            "Epoch 59/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.4972 - accuracy: 0.7658 - val_loss: 0.4655 - val_accuracy: 0.7642\n",
            "Epoch 60/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.4733 - accuracy: 0.7699 - val_loss: 0.4917 - val_accuracy: 0.7480\n",
            "Epoch 61/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.4967 - accuracy: 0.7576 - val_loss: 0.4909 - val_accuracy: 0.7642\n",
            "Epoch 62/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.5110 - accuracy: 0.7556 - val_loss: 0.4927 - val_accuracy: 0.7886\n",
            "Epoch 63/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.4866 - accuracy: 0.7678 - val_loss: 0.4706 - val_accuracy: 0.7642\n",
            "Epoch 64/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.5145 - accuracy: 0.7251 - val_loss: 0.5127 - val_accuracy: 0.7154\n",
            "Epoch 65/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.5196 - accuracy: 0.7454 - val_loss: 0.4888 - val_accuracy: 0.8049\n",
            "Epoch 66/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.4940 - accuracy: 0.7454 - val_loss: 0.5268 - val_accuracy: 0.7398\n",
            "Epoch 67/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.5019 - accuracy: 0.7454 - val_loss: 0.4766 - val_accuracy: 0.7967\n",
            "Epoch 68/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.4825 - accuracy: 0.7719 - val_loss: 0.5015 - val_accuracy: 0.7886\n",
            "Epoch 69/100\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.4915 - accuracy: 0.7658 - val_loss: 0.4563 - val_accuracy: 0.8130\n",
            "Epoch 70/100\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.4989 - accuracy: 0.7556 - val_loss: 0.4675 - val_accuracy: 0.7805\n",
            "Epoch 71/100\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.4988 - accuracy: 0.7454 - val_loss: 0.4618 - val_accuracy: 0.7642\n",
            "Epoch 72/100\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.4944 - accuracy: 0.7597 - val_loss: 0.5005 - val_accuracy: 0.7642\n",
            "Epoch 73/100\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.4924 - accuracy: 0.7658 - val_loss: 0.4593 - val_accuracy: 0.7805\n",
            "Epoch 74/100\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.4953 - accuracy: 0.7637 - val_loss: 0.4576 - val_accuracy: 0.8049\n",
            "Epoch 75/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.4913 - accuracy: 0.7495 - val_loss: 0.5240 - val_accuracy: 0.7236\n",
            "Epoch 76/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.4991 - accuracy: 0.7699 - val_loss: 0.5862 - val_accuracy: 0.7073\n",
            "Epoch 77/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.5074 - accuracy: 0.7617 - val_loss: 0.4655 - val_accuracy: 0.7805\n",
            "Epoch 78/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.4769 - accuracy: 0.7637 - val_loss: 0.4829 - val_accuracy: 0.7886\n",
            "Epoch 79/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.4971 - accuracy: 0.7637 - val_loss: 0.4722 - val_accuracy: 0.7642\n",
            "Epoch 80/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.4809 - accuracy: 0.7739 - val_loss: 0.5329 - val_accuracy: 0.7480\n",
            "Epoch 81/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.5024 - accuracy: 0.7413 - val_loss: 0.4638 - val_accuracy: 0.7724\n",
            "Epoch 82/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.4786 - accuracy: 0.7719 - val_loss: 0.4735 - val_accuracy: 0.7724\n",
            "Epoch 83/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.5015 - accuracy: 0.7637 - val_loss: 0.4532 - val_accuracy: 0.8130\n",
            "Epoch 84/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.4920 - accuracy: 0.7699 - val_loss: 0.4793 - val_accuracy: 0.7805\n",
            "Epoch 85/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.4734 - accuracy: 0.7760 - val_loss: 0.4679 - val_accuracy: 0.7724\n",
            "Epoch 86/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.5029 - accuracy: 0.7617 - val_loss: 0.4661 - val_accuracy: 0.7724\n",
            "Epoch 87/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.4638 - accuracy: 0.7699 - val_loss: 0.5023 - val_accuracy: 0.7805\n",
            "Epoch 88/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.4703 - accuracy: 0.7821 - val_loss: 0.5257 - val_accuracy: 0.7398\n",
            "Epoch 89/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.4886 - accuracy: 0.7780 - val_loss: 0.5022 - val_accuracy: 0.7480\n",
            "Epoch 90/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.5232 - accuracy: 0.7413 - val_loss: 0.4575 - val_accuracy: 0.7561\n",
            "Epoch 91/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.5228 - accuracy: 0.7617 - val_loss: 0.4986 - val_accuracy: 0.7561\n",
            "Epoch 92/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.4979 - accuracy: 0.7678 - val_loss: 0.4462 - val_accuracy: 0.7967\n",
            "Epoch 93/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.4804 - accuracy: 0.7597 - val_loss: 0.4624 - val_accuracy: 0.7967\n",
            "Epoch 94/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.4916 - accuracy: 0.7780 - val_loss: 0.5064 - val_accuracy: 0.7561\n",
            "Epoch 95/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.4770 - accuracy: 0.7617 - val_loss: 0.4790 - val_accuracy: 0.7805\n",
            "Epoch 96/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.4867 - accuracy: 0.7862 - val_loss: 0.4551 - val_accuracy: 0.8049\n",
            "Epoch 97/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.4889 - accuracy: 0.7637 - val_loss: 0.4717 - val_accuracy: 0.7724\n",
            "Epoch 98/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.4745 - accuracy: 0.7862 - val_loss: 0.4850 - val_accuracy: 0.7805\n",
            "Epoch 99/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.5143 - accuracy: 0.7576 - val_loss: 0.4748 - val_accuracy: 0.7805\n",
            "Epoch 100/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.4846 - accuracy: 0.7658 - val_loss: 0.4834 - val_accuracy: 0.7642\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7effe027f730>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_model.save(\"best_model_hp.h5\")"
      ],
      "metadata": {
        "id": "BbFIDJQ1qIq6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "modelOriginal = load_model(\"model.h5\")\n",
        "modelHp = load_model(\"best_model_hp.h5\")\n",
        "\n",
        "lossOriginal, accuracyOriginal = modelOriginal.evaluate(X_test, y_test)\n",
        "lossHp, accuracyHp = modelHp.evaluate(X_test, y_test)\n",
        "\n",
        "# create the DataFrame\n",
        "df = pd.DataFrame({'Model': ['Original','Hyperparameter Tuning (Keras Tuner)'],\n",
        "                   'Loss': [lossOriginal, lossHp],\n",
        "                   'Accuracy': [accuracyOriginal, accuracyHp]})\n",
        "\n",
        "# print the table using tabulate\n",
        "print(tabulate(df, headers='keys', tablefmt='pipe', floatfmt='.4f'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D7KDfk3zasph",
        "outputId": "718dcc2c-ff60-4370-b708-5fb1c03aa072"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6000 - accuracy: 0.7078\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5180 - accuracy: 0.7403\n",
            "|    | Model                               |   Loss |   Accuracy |\n",
            "|---:|:------------------------------------|-------:|-----------:|\n",
            "|  0 | Original                            | 0.6000 |     0.7078 |\n",
            "|  1 | Hyperparameter Tuning (Keras Tuner) | 0.5180 |     0.7403 |\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Compared to the original model, the model improved by Hyperparameter Tuning has shown an improvement in accuracy. The change is generated from optimizing and selecting the Hyperparameters.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "9MahKuE4bT2P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initially, the model only had 3 layers with the following parameters:\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EAx5LFRucn3-",
        "outputId": "3d570c21-ca32-46d1-d202-45a716ac4a99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 8)                 72        \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 8)                 72        \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1)                 9         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 153\n",
            "Trainable params: 153\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The optimized model has layers with the following parameters:\n",
        "best_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k90Ukiu_dgZ2",
        "outputId": "deb9e096-65f1-4ce7-b104-7c004a798f55"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 8)                 72        \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 24)                216       \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 24)                600       \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 25        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 913\n",
            "Trainable params: 913\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Improving model by Regularization (L2 Regularization)"
      ],
      "metadata": {
        "id": "R7mCUbOYd7PI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import regularizers"
      ],
      "metadata": {
        "id": "LuZD0gZFeHKz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Apply a lambda coefficient of 0.01 to both the first two Dense layers of the neural network architecture.\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(8, input_dim=8, activation='relu', kernel_regularizer=regularizers.l2(0.01)))\n",
        "model.add(Dense(8, activation='relu', kernel_regularizer=regularizers.l2(0.01)))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.fit(X_train, y_train, epochs=100, batch_size=8, validation_data=(X_val, y_val))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qtzygwGQeOVN",
        "outputId": "d604f45e-4607-4ac7-8b5a-cef4ce622761"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "62/62 [==============================] - 2s 7ms/step - loss: 3.2479 - accuracy: 0.4114 - val_loss: 2.4286 - val_accuracy: 0.4634\n",
            "Epoch 2/100\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 1.7630 - accuracy: 0.4745 - val_loss: 1.6000 - val_accuracy: 0.4797\n",
            "Epoch 3/100\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 1.3122 - accuracy: 0.5234 - val_loss: 1.1785 - val_accuracy: 0.4959\n",
            "Epoch 4/100\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.0171 - accuracy: 0.5764 - val_loss: 0.9445 - val_accuracy: 0.5366\n",
            "Epoch 5/100\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.8989 - accuracy: 0.5764 - val_loss: 0.8432 - val_accuracy: 0.6423\n",
            "Epoch 6/100\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.8604 - accuracy: 0.6293 - val_loss: 0.8163 - val_accuracy: 0.6911\n",
            "Epoch 7/100\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.8417 - accuracy: 0.6456 - val_loss: 0.7931 - val_accuracy: 0.6748\n",
            "Epoch 8/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.8327 - accuracy: 0.6497 - val_loss: 0.7827 - val_accuracy: 0.6667\n",
            "Epoch 9/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.8237 - accuracy: 0.6517 - val_loss: 0.7892 - val_accuracy: 0.6992\n",
            "Epoch 10/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.8146 - accuracy: 0.6558 - val_loss: 0.7846 - val_accuracy: 0.6748\n",
            "Epoch 11/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.8064 - accuracy: 0.6558 - val_loss: 0.7888 - val_accuracy: 0.6992\n",
            "Epoch 12/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.7976 - accuracy: 0.6558 - val_loss: 0.7843 - val_accuracy: 0.7073\n",
            "Epoch 13/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.7908 - accuracy: 0.6558 - val_loss: 0.7749 - val_accuracy: 0.6992\n",
            "Epoch 14/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.7831 - accuracy: 0.6599 - val_loss: 0.7634 - val_accuracy: 0.7073\n",
            "Epoch 15/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.7794 - accuracy: 0.6436 - val_loss: 0.7541 - val_accuracy: 0.6911\n",
            "Epoch 16/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.7635 - accuracy: 0.6599 - val_loss: 0.7540 - val_accuracy: 0.6829\n",
            "Epoch 17/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.7570 - accuracy: 0.6660 - val_loss: 0.7470 - val_accuracy: 0.7073\n",
            "Epoch 18/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.7454 - accuracy: 0.6660 - val_loss: 0.7530 - val_accuracy: 0.6992\n",
            "Epoch 19/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.7331 - accuracy: 0.6680 - val_loss: 0.7509 - val_accuracy: 0.6992\n",
            "Epoch 20/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.7208 - accuracy: 0.6701 - val_loss: 0.7458 - val_accuracy: 0.7154\n",
            "Epoch 21/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.7159 - accuracy: 0.6660 - val_loss: 0.7559 - val_accuracy: 0.7073\n",
            "Epoch 22/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.7109 - accuracy: 0.6680 - val_loss: 0.7502 - val_accuracy: 0.7154\n",
            "Epoch 23/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.7050 - accuracy: 0.6741 - val_loss: 0.7404 - val_accuracy: 0.7073\n",
            "Epoch 24/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.7061 - accuracy: 0.6599 - val_loss: 0.7398 - val_accuracy: 0.6829\n",
            "Epoch 25/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.7011 - accuracy: 0.6660 - val_loss: 0.7451 - val_accuracy: 0.6829\n",
            "Epoch 26/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.6943 - accuracy: 0.6721 - val_loss: 0.7444 - val_accuracy: 0.6992\n",
            "Epoch 27/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.6978 - accuracy: 0.6701 - val_loss: 0.7371 - val_accuracy: 0.6829\n",
            "Epoch 28/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.6886 - accuracy: 0.6660 - val_loss: 0.7382 - val_accuracy: 0.6911\n",
            "Epoch 29/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.6871 - accuracy: 0.6762 - val_loss: 0.7369 - val_accuracy: 0.6992\n",
            "Epoch 30/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.6847 - accuracy: 0.6721 - val_loss: 0.7281 - val_accuracy: 0.6911\n",
            "Epoch 31/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.6810 - accuracy: 0.6517 - val_loss: 0.7322 - val_accuracy: 0.7154\n",
            "Epoch 32/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.6799 - accuracy: 0.6843 - val_loss: 0.7268 - val_accuracy: 0.6992\n",
            "Epoch 33/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.6714 - accuracy: 0.6823 - val_loss: 0.7252 - val_accuracy: 0.6748\n",
            "Epoch 34/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.6751 - accuracy: 0.6762 - val_loss: 0.7174 - val_accuracy: 0.6992\n",
            "Epoch 35/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.6671 - accuracy: 0.6864 - val_loss: 0.7194 - val_accuracy: 0.7073\n",
            "Epoch 36/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.6665 - accuracy: 0.6640 - val_loss: 0.7198 - val_accuracy: 0.6748\n",
            "Epoch 37/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.6650 - accuracy: 0.6884 - val_loss: 0.7135 - val_accuracy: 0.7236\n",
            "Epoch 38/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.6621 - accuracy: 0.6721 - val_loss: 0.7080 - val_accuracy: 0.6911\n",
            "Epoch 39/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.6560 - accuracy: 0.6864 - val_loss: 0.7025 - val_accuracy: 0.7073\n",
            "Epoch 40/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.6515 - accuracy: 0.6802 - val_loss: 0.6995 - val_accuracy: 0.7398\n",
            "Epoch 41/100\n",
            "62/62 [==============================] - 1s 8ms/step - loss: 0.6497 - accuracy: 0.6762 - val_loss: 0.7040 - val_accuracy: 0.6992\n",
            "Epoch 42/100\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.6466 - accuracy: 0.6904 - val_loss: 0.6981 - val_accuracy: 0.7317\n",
            "Epoch 43/100\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.6438 - accuracy: 0.6823 - val_loss: 0.6942 - val_accuracy: 0.7236\n",
            "Epoch 44/100\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.6402 - accuracy: 0.6864 - val_loss: 0.6924 - val_accuracy: 0.6992\n",
            "Epoch 45/100\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.6360 - accuracy: 0.6945 - val_loss: 0.6847 - val_accuracy: 0.7561\n",
            "Epoch 46/100\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.6428 - accuracy: 0.6965 - val_loss: 0.6806 - val_accuracy: 0.7480\n",
            "Epoch 47/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.6311 - accuracy: 0.7026 - val_loss: 0.6748 - val_accuracy: 0.7642\n",
            "Epoch 48/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.6295 - accuracy: 0.7047 - val_loss: 0.6726 - val_accuracy: 0.7642\n",
            "Epoch 49/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.6297 - accuracy: 0.7108 - val_loss: 0.6761 - val_accuracy: 0.7480\n",
            "Epoch 50/100\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.6257 - accuracy: 0.7108 - val_loss: 0.6773 - val_accuracy: 0.7398\n",
            "Epoch 51/100\n",
            "62/62 [==============================] - 1s 10ms/step - loss: 0.6206 - accuracy: 0.7373 - val_loss: 0.6691 - val_accuracy: 0.7480\n",
            "Epoch 52/100\n",
            "62/62 [==============================] - 1s 9ms/step - loss: 0.6242 - accuracy: 0.7251 - val_loss: 0.6763 - val_accuracy: 0.7480\n",
            "Epoch 53/100\n",
            "62/62 [==============================] - 1s 9ms/step - loss: 0.6219 - accuracy: 0.7332 - val_loss: 0.6776 - val_accuracy: 0.7236\n",
            "Epoch 54/100\n",
            "62/62 [==============================] - 1s 8ms/step - loss: 0.6190 - accuracy: 0.7332 - val_loss: 0.6601 - val_accuracy: 0.7398\n",
            "Epoch 55/100\n",
            "62/62 [==============================] - 1s 8ms/step - loss: 0.6183 - accuracy: 0.7251 - val_loss: 0.6557 - val_accuracy: 0.7805\n",
            "Epoch 56/100\n",
            "62/62 [==============================] - 0s 8ms/step - loss: 0.6132 - accuracy: 0.7271 - val_loss: 0.6580 - val_accuracy: 0.7724\n",
            "Epoch 57/100\n",
            "62/62 [==============================] - 1s 9ms/step - loss: 0.6183 - accuracy: 0.7332 - val_loss: 0.6529 - val_accuracy: 0.7480\n",
            "Epoch 58/100\n",
            "62/62 [==============================] - 1s 10ms/step - loss: 0.6110 - accuracy: 0.7291 - val_loss: 0.6679 - val_accuracy: 0.7317\n",
            "Epoch 59/100\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.6081 - accuracy: 0.7475 - val_loss: 0.6531 - val_accuracy: 0.7480\n",
            "Epoch 60/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.6084 - accuracy: 0.7393 - val_loss: 0.6604 - val_accuracy: 0.7480\n",
            "Epoch 61/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.6103 - accuracy: 0.7312 - val_loss: 0.6506 - val_accuracy: 0.7724\n",
            "Epoch 62/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.6145 - accuracy: 0.7210 - val_loss: 0.6527 - val_accuracy: 0.7398\n",
            "Epoch 63/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.6068 - accuracy: 0.7251 - val_loss: 0.6524 - val_accuracy: 0.7561\n",
            "Epoch 64/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.6066 - accuracy: 0.7393 - val_loss: 0.6434 - val_accuracy: 0.7561\n",
            "Epoch 65/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.6013 - accuracy: 0.7352 - val_loss: 0.6423 - val_accuracy: 0.7480\n",
            "Epoch 66/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.6010 - accuracy: 0.7393 - val_loss: 0.6422 - val_accuracy: 0.7236\n",
            "Epoch 67/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.5997 - accuracy: 0.7434 - val_loss: 0.6523 - val_accuracy: 0.7317\n",
            "Epoch 68/100\n",
            "62/62 [==============================] - 1s 10ms/step - loss: 0.6017 - accuracy: 0.7251 - val_loss: 0.6383 - val_accuracy: 0.7642\n",
            "Epoch 69/100\n",
            "62/62 [==============================] - 1s 16ms/step - loss: 0.5995 - accuracy: 0.7495 - val_loss: 0.6321 - val_accuracy: 0.7642\n",
            "Epoch 70/100\n",
            "62/62 [==============================] - 1s 17ms/step - loss: 0.5995 - accuracy: 0.7413 - val_loss: 0.6416 - val_accuracy: 0.7642\n",
            "Epoch 71/100\n",
            "62/62 [==============================] - 1s 16ms/step - loss: 0.5934 - accuracy: 0.7515 - val_loss: 0.6339 - val_accuracy: 0.7317\n",
            "Epoch 72/100\n",
            "62/62 [==============================] - 1s 13ms/step - loss: 0.5947 - accuracy: 0.7332 - val_loss: 0.6349 - val_accuracy: 0.7317\n",
            "Epoch 73/100\n",
            "62/62 [==============================] - 1s 11ms/step - loss: 0.5942 - accuracy: 0.7271 - val_loss: 0.6410 - val_accuracy: 0.7642\n",
            "Epoch 74/100\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.5894 - accuracy: 0.7373 - val_loss: 0.6508 - val_accuracy: 0.7154\n",
            "Epoch 75/100\n",
            "62/62 [==============================] - 1s 12ms/step - loss: 0.5900 - accuracy: 0.7393 - val_loss: 0.6349 - val_accuracy: 0.7398\n",
            "Epoch 76/100\n",
            "62/62 [==============================] - 1s 12ms/step - loss: 0.5899 - accuracy: 0.7373 - val_loss: 0.6323 - val_accuracy: 0.7317\n",
            "Epoch 77/100\n",
            "62/62 [==============================] - 1s 12ms/step - loss: 0.5938 - accuracy: 0.7251 - val_loss: 0.6381 - val_accuracy: 0.7317\n",
            "Epoch 78/100\n",
            "62/62 [==============================] - 1s 12ms/step - loss: 0.5850 - accuracy: 0.7393 - val_loss: 0.6256 - val_accuracy: 0.7642\n",
            "Epoch 79/100\n",
            "62/62 [==============================] - 1s 12ms/step - loss: 0.5895 - accuracy: 0.7230 - val_loss: 0.6265 - val_accuracy: 0.7805\n",
            "Epoch 80/100\n",
            "62/62 [==============================] - 1s 11ms/step - loss: 0.5874 - accuracy: 0.7291 - val_loss: 0.6330 - val_accuracy: 0.7317\n",
            "Epoch 81/100\n",
            "62/62 [==============================] - 1s 12ms/step - loss: 0.5830 - accuracy: 0.7475 - val_loss: 0.6298 - val_accuracy: 0.7398\n",
            "Epoch 82/100\n",
            "62/62 [==============================] - 1s 14ms/step - loss: 0.5836 - accuracy: 0.7271 - val_loss: 0.6338 - val_accuracy: 0.7561\n",
            "Epoch 83/100\n",
            "62/62 [==============================] - 1s 12ms/step - loss: 0.5802 - accuracy: 0.7536 - val_loss: 0.6240 - val_accuracy: 0.7480\n",
            "Epoch 84/100\n",
            "62/62 [==============================] - 1s 11ms/step - loss: 0.5861 - accuracy: 0.7291 - val_loss: 0.6240 - val_accuracy: 0.7317\n",
            "Epoch 85/100\n",
            "62/62 [==============================] - 1s 8ms/step - loss: 0.5891 - accuracy: 0.7312 - val_loss: 0.6249 - val_accuracy: 0.7561\n",
            "Epoch 86/100\n",
            "62/62 [==============================] - 1s 12ms/step - loss: 0.5797 - accuracy: 0.7495 - val_loss: 0.6292 - val_accuracy: 0.7398\n",
            "Epoch 87/100\n",
            "62/62 [==============================] - 1s 12ms/step - loss: 0.5789 - accuracy: 0.7393 - val_loss: 0.6276 - val_accuracy: 0.7561\n",
            "Epoch 88/100\n",
            "62/62 [==============================] - 1s 13ms/step - loss: 0.5875 - accuracy: 0.7210 - val_loss: 0.6223 - val_accuracy: 0.7642\n",
            "Epoch 89/100\n",
            "62/62 [==============================] - 1s 15ms/step - loss: 0.5743 - accuracy: 0.7454 - val_loss: 0.6321 - val_accuracy: 0.7317\n",
            "Epoch 90/100\n",
            "62/62 [==============================] - 1s 9ms/step - loss: 0.5767 - accuracy: 0.7413 - val_loss: 0.6167 - val_accuracy: 0.7805\n",
            "Epoch 91/100\n",
            "62/62 [==============================] - 1s 9ms/step - loss: 0.5718 - accuracy: 0.7495 - val_loss: 0.6207 - val_accuracy: 0.7398\n",
            "Epoch 92/100\n",
            "62/62 [==============================] - 1s 11ms/step - loss: 0.5707 - accuracy: 0.7413 - val_loss: 0.6307 - val_accuracy: 0.7236\n",
            "Epoch 93/100\n",
            "62/62 [==============================] - 1s 11ms/step - loss: 0.5730 - accuracy: 0.7475 - val_loss: 0.6271 - val_accuracy: 0.7236\n",
            "Epoch 94/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.5721 - accuracy: 0.7413 - val_loss: 0.6180 - val_accuracy: 0.7480\n",
            "Epoch 95/100\n",
            "62/62 [==============================] - 1s 11ms/step - loss: 0.5661 - accuracy: 0.7475 - val_loss: 0.6508 - val_accuracy: 0.7317\n",
            "Epoch 96/100\n",
            "62/62 [==============================] - 1s 10ms/step - loss: 0.5755 - accuracy: 0.7413 - val_loss: 0.6177 - val_accuracy: 0.7317\n",
            "Epoch 97/100\n",
            "62/62 [==============================] - 1s 11ms/step - loss: 0.5750 - accuracy: 0.7291 - val_loss: 0.6201 - val_accuracy: 0.7317\n",
            "Epoch 98/100\n",
            "62/62 [==============================] - 1s 9ms/step - loss: 0.5750 - accuracy: 0.7373 - val_loss: 0.6126 - val_accuracy: 0.7561\n",
            "Epoch 99/100\n",
            "62/62 [==============================] - 1s 8ms/step - loss: 0.5662 - accuracy: 0.7413 - val_loss: 0.6404 - val_accuracy: 0.7154\n",
            "Epoch 100/100\n",
            "62/62 [==============================] - 1s 10ms/step - loss: 0.5737 - accuracy: 0.7434 - val_loss: 0.6259 - val_accuracy: 0.7154\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7effe003f520>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"best_model_regularization.h5\")"
      ],
      "metadata": {
        "id": "wKHLMPeWqT6S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "modelOriginal = load_model(\"model.h5\")\n",
        "modelRe = load_model(\"best_model_regularization.h5\")\n",
        "\n",
        "lossOriginal, accuracyOriginal = modelOriginal.evaluate(X_test, y_test)\n",
        "lossRe, accuracyRe = modelRe.evaluate(X_test, y_test)\n",
        "\n",
        "# create the DataFrame\n",
        "df = pd.DataFrame({'Model': ['Original','Regularization (L2 Regularization)'],\n",
        "                   'Loss': [lossOriginal, lossRe],\n",
        "                   'Accuracy': [accuracyOriginal, accuracyRe]})\n",
        "\n",
        "# print the table using tabulate\n",
        "print(tabulate(df, headers='keys', tablefmt='pipe', floatfmt='.4f'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kmmpHoXae4XB",
        "outputId": "677b34dc-ca9a-43f1-d6fe-26ecd1188b98"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5/5 [==============================] - 0s 7ms/step - loss: 0.6000 - accuracy: 0.7078\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6274 - accuracy: 0.7013\n",
            "|    | Model                              |   Loss |   Accuracy |\n",
            "|---:|:-----------------------------------|-------:|-----------:|\n",
            "|  0 | Original                           | 0.6000 |     0.7078 |\n",
            "|  1 | Regularization (L2 Regularization) | 0.6274 |     0.7013 |\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Compared to the original model, the model improved by Regularization, specifically using L2 Regularization, has shown a change in accuracy. The change is generated from adding a squared component of the weights to the loss function. This will make the weights smaller, resulting in a simpler model and avoiding overfitting."
      ],
      "metadata": {
        "id": "KfyDN-5Cf0zY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Improving model by Optimization (Adam -> RMSprop)"
      ],
      "metadata": {
        "id": "3bqYas4liwU6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(8, input_dim=8, activation='relu'))\n",
        "model.add(Dense(8, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer=RMSprop(learning_rate=0.001), metrics=['accuracy'])\n",
        "model.fit(X_train, y_train, epochs=100, batch_size=8, validation_data=(X_val, y_val))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-XjBSfcjifxc",
        "outputId": "66de4bf0-62a9-4e0d-a9d2-3f2197ae268f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "62/62 [==============================] - 2s 11ms/step - loss: 8.0581 - accuracy: 0.3625 - val_loss: 3.2001 - val_accuracy: 0.3659\n",
            "Epoch 2/100\n",
            "62/62 [==============================] - 1s 8ms/step - loss: 1.6174 - accuracy: 0.5418 - val_loss: 1.0252 - val_accuracy: 0.6016\n",
            "Epoch 3/100\n",
            "62/62 [==============================] - 1s 9ms/step - loss: 1.1783 - accuracy: 0.5866 - val_loss: 0.9437 - val_accuracy: 0.5854\n",
            "Epoch 4/100\n",
            "62/62 [==============================] - 0s 8ms/step - loss: 1.0456 - accuracy: 0.5947 - val_loss: 0.8105 - val_accuracy: 0.6423\n",
            "Epoch 5/100\n",
            "62/62 [==============================] - 1s 15ms/step - loss: 0.9290 - accuracy: 0.5927 - val_loss: 0.7376 - val_accuracy: 0.6667\n",
            "Epoch 6/100\n",
            "62/62 [==============================] - 1s 19ms/step - loss: 0.8373 - accuracy: 0.5947 - val_loss: 0.7356 - val_accuracy: 0.5935\n",
            "Epoch 7/100\n",
            "62/62 [==============================] - 1s 10ms/step - loss: 0.7696 - accuracy: 0.5927 - val_loss: 0.6732 - val_accuracy: 0.5772\n",
            "Epoch 8/100\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.7023 - accuracy: 0.6334 - val_loss: 0.6491 - val_accuracy: 0.6667\n",
            "Epoch 9/100\n",
            "62/62 [==============================] - 1s 8ms/step - loss: 0.6692 - accuracy: 0.6619 - val_loss: 0.7831 - val_accuracy: 0.5366\n",
            "Epoch 10/100\n",
            "62/62 [==============================] - 1s 8ms/step - loss: 0.6542 - accuracy: 0.6415 - val_loss: 0.6807 - val_accuracy: 0.6585\n",
            "Epoch 11/100\n",
            "62/62 [==============================] - 1s 10ms/step - loss: 0.6366 - accuracy: 0.6721 - val_loss: 0.6885 - val_accuracy: 0.6992\n",
            "Epoch 12/100\n",
            "62/62 [==============================] - 1s 9ms/step - loss: 0.6405 - accuracy: 0.6721 - val_loss: 0.6417 - val_accuracy: 0.6992\n",
            "Epoch 13/100\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.6258 - accuracy: 0.6802 - val_loss: 0.6121 - val_accuracy: 0.6911\n",
            "Epoch 14/100\n",
            "62/62 [==============================] - 1s 11ms/step - loss: 0.6212 - accuracy: 0.6741 - val_loss: 0.6180 - val_accuracy: 0.6829\n",
            "Epoch 15/100\n",
            "62/62 [==============================] - 1s 10ms/step - loss: 0.6214 - accuracy: 0.6782 - val_loss: 0.6193 - val_accuracy: 0.6748\n",
            "Epoch 16/100\n",
            "62/62 [==============================] - 0s 8ms/step - loss: 0.6214 - accuracy: 0.6864 - val_loss: 0.6396 - val_accuracy: 0.6423\n",
            "Epoch 17/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.6203 - accuracy: 0.6823 - val_loss: 0.6043 - val_accuracy: 0.6829\n",
            "Epoch 18/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.6160 - accuracy: 0.6823 - val_loss: 0.6076 - val_accuracy: 0.6829\n",
            "Epoch 19/100\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.6024 - accuracy: 0.6965 - val_loss: 0.5883 - val_accuracy: 0.7317\n",
            "Epoch 20/100\n",
            "62/62 [==============================] - 1s 8ms/step - loss: 0.6057 - accuracy: 0.6965 - val_loss: 0.5879 - val_accuracy: 0.7073\n",
            "Epoch 21/100\n",
            "62/62 [==============================] - 0s 8ms/step - loss: 0.6089 - accuracy: 0.6965 - val_loss: 0.5955 - val_accuracy: 0.6911\n",
            "Epoch 22/100\n",
            "62/62 [==============================] - 0s 8ms/step - loss: 0.5916 - accuracy: 0.7108 - val_loss: 0.6399 - val_accuracy: 0.6667\n",
            "Epoch 23/100\n",
            "62/62 [==============================] - 1s 10ms/step - loss: 0.5998 - accuracy: 0.6925 - val_loss: 0.5882 - val_accuracy: 0.7154\n",
            "Epoch 24/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.5869 - accuracy: 0.6965 - val_loss: 0.6160 - val_accuracy: 0.6911\n",
            "Epoch 25/100\n",
            "62/62 [==============================] - 0s 8ms/step - loss: 0.5867 - accuracy: 0.6904 - val_loss: 0.6206 - val_accuracy: 0.6341\n",
            "Epoch 26/100\n",
            "62/62 [==============================] - 0s 8ms/step - loss: 0.5935 - accuracy: 0.6904 - val_loss: 0.5774 - val_accuracy: 0.7154\n",
            "Epoch 27/100\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.5868 - accuracy: 0.6904 - val_loss: 0.5966 - val_accuracy: 0.6992\n",
            "Epoch 28/100\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.5796 - accuracy: 0.7108 - val_loss: 0.5692 - val_accuracy: 0.7236\n",
            "Epoch 29/100\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.5804 - accuracy: 0.6904 - val_loss: 0.5760 - val_accuracy: 0.6992\n",
            "Epoch 30/100\n",
            "62/62 [==============================] - 1s 11ms/step - loss: 0.5821 - accuracy: 0.7047 - val_loss: 0.5812 - val_accuracy: 0.6911\n",
            "Epoch 31/100\n",
            "62/62 [==============================] - 1s 15ms/step - loss: 0.5678 - accuracy: 0.7088 - val_loss: 0.5787 - val_accuracy: 0.6992\n",
            "Epoch 32/100\n",
            "62/62 [==============================] - 1s 11ms/step - loss: 0.5706 - accuracy: 0.7169 - val_loss: 0.5778 - val_accuracy: 0.7154\n",
            "Epoch 33/100\n",
            "62/62 [==============================] - 1s 11ms/step - loss: 0.5706 - accuracy: 0.7189 - val_loss: 0.5632 - val_accuracy: 0.7154\n",
            "Epoch 34/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.5671 - accuracy: 0.7088 - val_loss: 0.5862 - val_accuracy: 0.6992\n",
            "Epoch 35/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.5711 - accuracy: 0.7271 - val_loss: 0.5930 - val_accuracy: 0.6992\n",
            "Epoch 36/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.5714 - accuracy: 0.6965 - val_loss: 0.6010 - val_accuracy: 0.6341\n",
            "Epoch 37/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.5615 - accuracy: 0.7271 - val_loss: 0.5517 - val_accuracy: 0.7317\n",
            "Epoch 38/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.5638 - accuracy: 0.7128 - val_loss: 0.5558 - val_accuracy: 0.7073\n",
            "Epoch 39/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.5579 - accuracy: 0.7169 - val_loss: 0.5510 - val_accuracy: 0.7236\n",
            "Epoch 40/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.5549 - accuracy: 0.7352 - val_loss: 0.5532 - val_accuracy: 0.7073\n",
            "Epoch 41/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.5587 - accuracy: 0.7251 - val_loss: 0.5462 - val_accuracy: 0.7398\n",
            "Epoch 42/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.5630 - accuracy: 0.7271 - val_loss: 0.5537 - val_accuracy: 0.7073\n",
            "Epoch 43/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.5469 - accuracy: 0.7251 - val_loss: 0.5580 - val_accuracy: 0.6992\n",
            "Epoch 44/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.5565 - accuracy: 0.7169 - val_loss: 0.5464 - val_accuracy: 0.7154\n",
            "Epoch 45/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.5558 - accuracy: 0.7149 - val_loss: 0.5543 - val_accuracy: 0.7317\n",
            "Epoch 46/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.5468 - accuracy: 0.7291 - val_loss: 0.5684 - val_accuracy: 0.7317\n",
            "Epoch 47/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.5531 - accuracy: 0.7149 - val_loss: 0.5410 - val_accuracy: 0.7154\n",
            "Epoch 48/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.5455 - accuracy: 0.7291 - val_loss: 0.5584 - val_accuracy: 0.7317\n",
            "Epoch 49/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.5421 - accuracy: 0.7149 - val_loss: 0.5601 - val_accuracy: 0.6911\n",
            "Epoch 50/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.5493 - accuracy: 0.7251 - val_loss: 0.5413 - val_accuracy: 0.7154\n",
            "Epoch 51/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.5441 - accuracy: 0.7373 - val_loss: 0.5387 - val_accuracy: 0.7236\n",
            "Epoch 52/100\n",
            "62/62 [==============================] - 1s 10ms/step - loss: 0.5461 - accuracy: 0.7230 - val_loss: 0.5659 - val_accuracy: 0.7073\n",
            "Epoch 53/100\n",
            "62/62 [==============================] - 1s 11ms/step - loss: 0.5403 - accuracy: 0.7271 - val_loss: 0.5329 - val_accuracy: 0.7317\n",
            "Epoch 54/100\n",
            "62/62 [==============================] - 1s 8ms/step - loss: 0.5401 - accuracy: 0.7352 - val_loss: 0.5658 - val_accuracy: 0.6992\n",
            "Epoch 55/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.5456 - accuracy: 0.7291 - val_loss: 0.5483 - val_accuracy: 0.7073\n",
            "Epoch 56/100\n",
            "62/62 [==============================] - 0s 8ms/step - loss: 0.5409 - accuracy: 0.7373 - val_loss: 0.5431 - val_accuracy: 0.7236\n",
            "Epoch 57/100\n",
            "62/62 [==============================] - 1s 9ms/step - loss: 0.5462 - accuracy: 0.7352 - val_loss: 0.5577 - val_accuracy: 0.6992\n",
            "Epoch 58/100\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.5335 - accuracy: 0.7332 - val_loss: 0.5399 - val_accuracy: 0.7480\n",
            "Epoch 59/100\n",
            "62/62 [==============================] - 0s 8ms/step - loss: 0.5341 - accuracy: 0.7088 - val_loss: 0.5336 - val_accuracy: 0.7236\n",
            "Epoch 60/100\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.5268 - accuracy: 0.7230 - val_loss: 0.5317 - val_accuracy: 0.7480\n",
            "Epoch 61/100\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.5405 - accuracy: 0.7312 - val_loss: 0.5422 - val_accuracy: 0.7073\n",
            "Epoch 62/100\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.5255 - accuracy: 0.7454 - val_loss: 0.5248 - val_accuracy: 0.7398\n",
            "Epoch 63/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.5328 - accuracy: 0.7454 - val_loss: 0.5290 - val_accuracy: 0.7398\n",
            "Epoch 64/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.5294 - accuracy: 0.7352 - val_loss: 0.5612 - val_accuracy: 0.7073\n",
            "Epoch 65/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.5326 - accuracy: 0.7271 - val_loss: 0.5211 - val_accuracy: 0.7480\n",
            "Epoch 66/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.5313 - accuracy: 0.7291 - val_loss: 0.5251 - val_accuracy: 0.7480\n",
            "Epoch 67/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.5249 - accuracy: 0.7434 - val_loss: 0.5308 - val_accuracy: 0.7154\n",
            "Epoch 68/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.5253 - accuracy: 0.7271 - val_loss: 0.5600 - val_accuracy: 0.7154\n",
            "Epoch 69/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.5233 - accuracy: 0.7312 - val_loss: 0.5359 - val_accuracy: 0.7480\n",
            "Epoch 70/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.5272 - accuracy: 0.7271 - val_loss: 0.5229 - val_accuracy: 0.7236\n",
            "Epoch 71/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.5319 - accuracy: 0.7251 - val_loss: 0.5708 - val_accuracy: 0.7073\n",
            "Epoch 72/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.5265 - accuracy: 0.7515 - val_loss: 0.5326 - val_accuracy: 0.7236\n",
            "Epoch 73/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.5254 - accuracy: 0.7515 - val_loss: 0.5237 - val_accuracy: 0.7317\n",
            "Epoch 74/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.5237 - accuracy: 0.7454 - val_loss: 0.5902 - val_accuracy: 0.6829\n",
            "Epoch 75/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.5252 - accuracy: 0.7230 - val_loss: 0.5188 - val_accuracy: 0.7642\n",
            "Epoch 76/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.5233 - accuracy: 0.7475 - val_loss: 0.5115 - val_accuracy: 0.7642\n",
            "Epoch 77/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.5203 - accuracy: 0.7434 - val_loss: 0.5154 - val_accuracy: 0.7480\n",
            "Epoch 78/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.5183 - accuracy: 0.7373 - val_loss: 0.5127 - val_accuracy: 0.7561\n",
            "Epoch 79/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.5219 - accuracy: 0.7332 - val_loss: 0.5209 - val_accuracy: 0.7317\n",
            "Epoch 80/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.5173 - accuracy: 0.7312 - val_loss: 0.5089 - val_accuracy: 0.7398\n",
            "Epoch 81/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.5089 - accuracy: 0.7536 - val_loss: 0.5415 - val_accuracy: 0.7154\n",
            "Epoch 82/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.5206 - accuracy: 0.7373 - val_loss: 0.5184 - val_accuracy: 0.7398\n",
            "Epoch 83/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.5236 - accuracy: 0.7373 - val_loss: 0.5550 - val_accuracy: 0.7317\n",
            "Epoch 84/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.5183 - accuracy: 0.7536 - val_loss: 0.5348 - val_accuracy: 0.7236\n",
            "Epoch 85/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.5139 - accuracy: 0.7475 - val_loss: 0.5304 - val_accuracy: 0.7154\n",
            "Epoch 86/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.5159 - accuracy: 0.7169 - val_loss: 0.5183 - val_accuracy: 0.7561\n",
            "Epoch 87/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.5120 - accuracy: 0.7393 - val_loss: 0.5480 - val_accuracy: 0.7398\n",
            "Epoch 88/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.5136 - accuracy: 0.7352 - val_loss: 0.5026 - val_accuracy: 0.7480\n",
            "Epoch 89/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.5168 - accuracy: 0.7413 - val_loss: 0.4995 - val_accuracy: 0.7724\n",
            "Epoch 90/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.5146 - accuracy: 0.7617 - val_loss: 0.5084 - val_accuracy: 0.7642\n",
            "Epoch 91/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.5175 - accuracy: 0.7393 - val_loss: 0.5170 - val_accuracy: 0.7317\n",
            "Epoch 92/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.5132 - accuracy: 0.7495 - val_loss: 0.5335 - val_accuracy: 0.7398\n",
            "Epoch 93/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.5172 - accuracy: 0.7373 - val_loss: 0.5135 - val_accuracy: 0.7561\n",
            "Epoch 94/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.5079 - accuracy: 0.7536 - val_loss: 0.5962 - val_accuracy: 0.6829\n",
            "Epoch 95/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.5064 - accuracy: 0.7597 - val_loss: 0.5734 - val_accuracy: 0.7236\n",
            "Epoch 96/100\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.5157 - accuracy: 0.7373 - val_loss: 0.5065 - val_accuracy: 0.7398\n",
            "Epoch 97/100\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.5143 - accuracy: 0.7495 - val_loss: 0.5099 - val_accuracy: 0.7480\n",
            "Epoch 98/100\n",
            "62/62 [==============================] - 1s 9ms/step - loss: 0.5096 - accuracy: 0.7515 - val_loss: 0.5910 - val_accuracy: 0.7398\n",
            "Epoch 99/100\n",
            "62/62 [==============================] - 1s 11ms/step - loss: 0.5133 - accuracy: 0.7617 - val_loss: 0.5334 - val_accuracy: 0.7398\n",
            "Epoch 100/100\n",
            "62/62 [==============================] - 1s 11ms/step - loss: 0.5061 - accuracy: 0.7699 - val_loss: 0.5681 - val_accuracy: 0.7317\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7effd3e5cd00>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"best_model_optimization.h5\")"
      ],
      "metadata": {
        "id": "ETd2_XspqkiK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "modelOriginal = load_model(\"model.h5\")\n",
        "modelOp = load_model(\"best_model_optimization.h5\")\n",
        "\n",
        "lossOriginal, accuracyOriginal = modelOriginal.evaluate(X_test, y_test)\n",
        "lossOp, accuracyOp = modelOp.evaluate(X_test, y_test)\n",
        "\n",
        "# create the DataFrame\n",
        "df = pd.DataFrame({'Model': ['Original','Optimization (Adam -> RMSprop)'],\n",
        "                   'Loss': [lossOriginal, lossOp],\n",
        "                   'Accuracy': [accuracyOriginal, accuracyOp]})\n",
        "\n",
        "# print the table using tabulate\n",
        "print(tabulate(df, headers='keys', tablefmt='pipe', floatfmt='.4f'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4-4C4kRMi2hj",
        "outputId": "29f835fc-3a5d-4188-fc95-a7a401e1686b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6000 - accuracy: 0.7078\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6346 - accuracy: 0.7208\n",
            "|    | Model                          |   Loss |   Accuracy |\n",
            "|---:|:-------------------------------|-------:|-----------:|\n",
            "|  0 | Original                       | 0.6000 |     0.7078 |\n",
            "|  1 | Optimization (Adam -> RMSprop) | 0.6346 |     0.7208 |\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Compared to the original model, the model improved by Optimization has shown a change in accuracy, specifically by changing the optimizer from Adam to RMSprop. The optimization algorithm will change the way to calculate the gradients and update the weights during the training process. Specifically, these two algorithms use different methods to calculate gradients and update weights, so changing the optimizer will have an impact on the model's performance."
      ],
      "metadata": {
        "id": "6O_FsWg_jHwn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Combining all three ways:"
      ],
      "metadata": {
        "id": "DgCWjPexjbb6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create function build Hyper model\n",
        "def build_best_model(hp): \n",
        "  model = keras.Sequential()\n",
        "\n",
        "  X = hp.Int('units_input', min_value=8, max_value=64, step=8)\n",
        "  model.add(Dense(units=X, input_dim=8, activation='relu', kernel_regularizer=regularizers.l2(0.01)))\n",
        "\n",
        "  for i in range(hp.Int('num_layers', 1, 4)):\n",
        "    Y = hp.Int('units_' + str(i), min_value=8, max_value=64, step=8)\n",
        "    model.add(Dense(units=Y, activation='relu', kernel_regularizer=regularizers.l2(0.01)))\n",
        "\n",
        "  model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "  # Finding optimizer\n",
        "  optimizer = hp.Choice('optimizer', values=['adam', 'rmsprop'])\n",
        "\n",
        "  # Finding learning_rate\n",
        "  lr = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
        "\n",
        "  if optimizer == 'adam':\n",
        "    model.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=lr), metrics=['accuracy'])\n",
        "  else:\n",
        "    model.compile(loss='binary_crossentropy', optimizer=RMSprop(learning_rate=lr), metrics=['accuracy'])\n",
        "  \n",
        "  return model"
      ],
      "metadata": {
        "id": "OITYCSdPjqO7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create Tuner\n",
        "tuner = kt.Hyperband (build_best_model, objective=\"val_accuracy\", directory=\"tuner_dir_2\", project_name=\"MLE501_Tuner_2\")"
      ],
      "metadata": {
        "id": "_GVRQIGJlOds"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tuner.search(X_train, y_train, epochs=10, validation_data=(X_val, y_val))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RxCcOO_DlXuw",
        "outputId": "c9ea2286-e43c-4895-9217-0cb7fc1597c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 254 Complete [00h 00m 22s]\n",
            "val_accuracy: 0.8211382031440735\n",
            "\n",
            "Best val_accuracy So Far: 0.8292682766914368\n",
            "Total elapsed time: 00h 13m 58s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get best hyperparameters\n",
        "best_hps = tuner.get_best_hyperparameters()[0]\n",
        "\n",
        "print(\"units_input: \", best_hps.get('units_input'))\n",
        "print(\"num_layers: \", best_hps.get('num_layers'))\n",
        "print(\"optimizer: \", best_hps.get('optimizer'))\n",
        "print(\"learning_rate: \", best_hps.get('learning_rate'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jmvaw6wOpV4j",
        "outputId": "2d940641-727c-417d-f822-376f5273592a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "units_input:  64\n",
            "num_layers:  3\n",
            "optimizer:  adam\n",
            "learning_rate:  0.01\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get super model\n",
        "best_model = tuner.get_best_models(num_models=1)[0]\n",
        "\n",
        "best_model.summary()\n",
        "\n",
        "best_model.fit(X_train, y_train, epochs=100, batch_size=8, validation_data=(X_val, y_val))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MuqUmmfWquFv",
        "outputId": "5b0482c1-7fac-4964-b072-3046a3505aa0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 64)                576       \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 24)                1560      \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 56)                1400      \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 64)                3648      \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 7,249\n",
            "Trainable params: 7,249\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "62/62 [==============================] - 1s 9ms/step - loss: 0.6534 - accuracy: 0.6965 - val_loss: 0.5591 - val_accuracy: 0.7480\n",
            "Epoch 2/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.6053 - accuracy: 0.7230 - val_loss: 0.5359 - val_accuracy: 0.7967\n",
            "Epoch 3/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.5946 - accuracy: 0.7291 - val_loss: 0.5338 - val_accuracy: 0.7724\n",
            "Epoch 4/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.5842 - accuracy: 0.7454 - val_loss: 0.6011 - val_accuracy: 0.6992\n",
            "Epoch 5/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.6125 - accuracy: 0.7128 - val_loss: 0.5125 - val_accuracy: 0.7967\n",
            "Epoch 6/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.5818 - accuracy: 0.7251 - val_loss: 0.5334 - val_accuracy: 0.7886\n",
            "Epoch 7/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.6014 - accuracy: 0.6925 - val_loss: 0.7022 - val_accuracy: 0.6829\n",
            "Epoch 8/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.6262 - accuracy: 0.6782 - val_loss: 0.5323 - val_accuracy: 0.7561\n",
            "Epoch 9/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.6218 - accuracy: 0.6945 - val_loss: 0.5317 - val_accuracy: 0.7805\n",
            "Epoch 10/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.5725 - accuracy: 0.7434 - val_loss: 0.5086 - val_accuracy: 0.7805\n",
            "Epoch 11/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.5748 - accuracy: 0.7271 - val_loss: 0.5119 - val_accuracy: 0.7642\n",
            "Epoch 12/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.5651 - accuracy: 0.7332 - val_loss: 0.5239 - val_accuracy: 0.7480\n",
            "Epoch 13/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.5661 - accuracy: 0.7393 - val_loss: 0.5152 - val_accuracy: 0.7480\n",
            "Epoch 14/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.5820 - accuracy: 0.7088 - val_loss: 0.4738 - val_accuracy: 0.8049\n",
            "Epoch 15/100\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.5508 - accuracy: 0.7413 - val_loss: 0.5031 - val_accuracy: 0.7480\n",
            "Epoch 16/100\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.5484 - accuracy: 0.7271 - val_loss: 0.4723 - val_accuracy: 0.8374\n",
            "Epoch 17/100\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.5667 - accuracy: 0.7271 - val_loss: 0.4875 - val_accuracy: 0.8130\n",
            "Epoch 18/100\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.5445 - accuracy: 0.7454 - val_loss: 0.5102 - val_accuracy: 0.7886\n",
            "Epoch 19/100\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.5413 - accuracy: 0.7495 - val_loss: 0.5083 - val_accuracy: 0.7724\n",
            "Epoch 20/100\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.5817 - accuracy: 0.7088 - val_loss: 0.4911 - val_accuracy: 0.8049\n",
            "Epoch 21/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.5573 - accuracy: 0.7352 - val_loss: 0.4728 - val_accuracy: 0.8049\n",
            "Epoch 22/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.5366 - accuracy: 0.7576 - val_loss: 0.5682 - val_accuracy: 0.7398\n",
            "Epoch 23/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.5948 - accuracy: 0.7230 - val_loss: 0.5201 - val_accuracy: 0.7805\n",
            "Epoch 24/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.5554 - accuracy: 0.7475 - val_loss: 0.4675 - val_accuracy: 0.8374\n",
            "Epoch 25/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.5582 - accuracy: 0.7373 - val_loss: 0.4797 - val_accuracy: 0.8049\n",
            "Epoch 26/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.5450 - accuracy: 0.7536 - val_loss: 0.4787 - val_accuracy: 0.7886\n",
            "Epoch 27/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.5759 - accuracy: 0.7393 - val_loss: 0.4902 - val_accuracy: 0.7967\n",
            "Epoch 28/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.5558 - accuracy: 0.7393 - val_loss: 0.4926 - val_accuracy: 0.7805\n",
            "Epoch 29/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.5553 - accuracy: 0.7189 - val_loss: 0.4687 - val_accuracy: 0.8049\n",
            "Epoch 30/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.5571 - accuracy: 0.7271 - val_loss: 0.4791 - val_accuracy: 0.7967\n",
            "Epoch 31/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.5598 - accuracy: 0.7332 - val_loss: 0.5635 - val_accuracy: 0.6992\n",
            "Epoch 32/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.5593 - accuracy: 0.7230 - val_loss: 0.4921 - val_accuracy: 0.7724\n",
            "Epoch 33/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.5425 - accuracy: 0.7434 - val_loss: 0.4818 - val_accuracy: 0.7805\n",
            "Epoch 34/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.5359 - accuracy: 0.7393 - val_loss: 0.4872 - val_accuracy: 0.7724\n",
            "Epoch 35/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.5370 - accuracy: 0.7475 - val_loss: 0.4709 - val_accuracy: 0.7805\n",
            "Epoch 36/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.5422 - accuracy: 0.7597 - val_loss: 0.4744 - val_accuracy: 0.7886\n",
            "Epoch 37/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.5257 - accuracy: 0.7637 - val_loss: 0.5436 - val_accuracy: 0.7236\n",
            "Epoch 38/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.5407 - accuracy: 0.7332 - val_loss: 0.4727 - val_accuracy: 0.7886\n",
            "Epoch 39/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.5376 - accuracy: 0.7495 - val_loss: 0.4888 - val_accuracy: 0.7886\n",
            "Epoch 40/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.5473 - accuracy: 0.7373 - val_loss: 0.4774 - val_accuracy: 0.7805\n",
            "Epoch 41/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.5264 - accuracy: 0.7637 - val_loss: 0.4573 - val_accuracy: 0.8211\n",
            "Epoch 42/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.5507 - accuracy: 0.7413 - val_loss: 0.4852 - val_accuracy: 0.7805\n",
            "Epoch 43/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.5433 - accuracy: 0.7536 - val_loss: 0.4876 - val_accuracy: 0.7886\n",
            "Epoch 44/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.5399 - accuracy: 0.7515 - val_loss: 0.4728 - val_accuracy: 0.7805\n",
            "Epoch 45/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.5606 - accuracy: 0.7108 - val_loss: 0.4803 - val_accuracy: 0.7967\n",
            "Epoch 46/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.5595 - accuracy: 0.7271 - val_loss: 0.4858 - val_accuracy: 0.8211\n",
            "Epoch 47/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.5325 - accuracy: 0.7454 - val_loss: 0.4616 - val_accuracy: 0.8130\n",
            "Epoch 48/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.5310 - accuracy: 0.7373 - val_loss: 0.4875 - val_accuracy: 0.7805\n",
            "Epoch 49/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.5555 - accuracy: 0.7312 - val_loss: 0.4934 - val_accuracy: 0.7724\n",
            "Epoch 50/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.5367 - accuracy: 0.7495 - val_loss: 0.4574 - val_accuracy: 0.8130\n",
            "Epoch 51/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.5335 - accuracy: 0.7658 - val_loss: 0.4767 - val_accuracy: 0.7642\n",
            "Epoch 52/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.5239 - accuracy: 0.7536 - val_loss: 0.5011 - val_accuracy: 0.7724\n",
            "Epoch 53/100\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.5418 - accuracy: 0.7189 - val_loss: 0.4785 - val_accuracy: 0.7724\n",
            "Epoch 54/100\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.5729 - accuracy: 0.7413 - val_loss: 0.4822 - val_accuracy: 0.7967\n",
            "Epoch 55/100\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.5314 - accuracy: 0.7434 - val_loss: 0.4809 - val_accuracy: 0.7886\n",
            "Epoch 56/100\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.5485 - accuracy: 0.7475 - val_loss: 0.5535 - val_accuracy: 0.7398\n",
            "Epoch 57/100\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.5585 - accuracy: 0.7332 - val_loss: 0.5174 - val_accuracy: 0.7398\n",
            "Epoch 58/100\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.5462 - accuracy: 0.7230 - val_loss: 0.4733 - val_accuracy: 0.8049\n",
            "Epoch 59/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.5539 - accuracy: 0.7393 - val_loss: 0.4798 - val_accuracy: 0.7886\n",
            "Epoch 60/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.5395 - accuracy: 0.7536 - val_loss: 0.5009 - val_accuracy: 0.7561\n",
            "Epoch 61/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.5314 - accuracy: 0.7393 - val_loss: 0.4590 - val_accuracy: 0.8049\n",
            "Epoch 62/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.5534 - accuracy: 0.7475 - val_loss: 0.4620 - val_accuracy: 0.8293\n",
            "Epoch 63/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.5332 - accuracy: 0.7454 - val_loss: 0.4581 - val_accuracy: 0.8049\n",
            "Epoch 64/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.5683 - accuracy: 0.7251 - val_loss: 0.4891 - val_accuracy: 0.7724\n",
            "Epoch 65/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.5377 - accuracy: 0.7475 - val_loss: 0.4539 - val_accuracy: 0.8293\n",
            "Epoch 66/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.5239 - accuracy: 0.7454 - val_loss: 0.5207 - val_accuracy: 0.7317\n",
            "Epoch 67/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.5162 - accuracy: 0.7536 - val_loss: 0.4531 - val_accuracy: 0.8130\n",
            "Epoch 68/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.5338 - accuracy: 0.7434 - val_loss: 0.4647 - val_accuracy: 0.7886\n",
            "Epoch 69/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.5430 - accuracy: 0.7312 - val_loss: 0.4607 - val_accuracy: 0.7967\n",
            "Epoch 70/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.5376 - accuracy: 0.7291 - val_loss: 0.4702 - val_accuracy: 0.7967\n",
            "Epoch 71/100\n",
            "62/62 [==============================] - 0s 4ms/step - loss: 0.5296 - accuracy: 0.7413 - val_loss: 0.4669 - val_accuracy: 0.7886\n",
            "Epoch 72/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.5449 - accuracy: 0.7719 - val_loss: 0.4747 - val_accuracy: 0.7967\n",
            "Epoch 73/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.5339 - accuracy: 0.7434 - val_loss: 0.5006 - val_accuracy: 0.7561\n",
            "Epoch 74/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.5261 - accuracy: 0.7515 - val_loss: 0.5028 - val_accuracy: 0.7480\n",
            "Epoch 75/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.5462 - accuracy: 0.7434 - val_loss: 0.4568 - val_accuracy: 0.8211\n",
            "Epoch 76/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.5343 - accuracy: 0.7352 - val_loss: 0.4618 - val_accuracy: 0.7886\n",
            "Epoch 77/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.5244 - accuracy: 0.7576 - val_loss: 0.4506 - val_accuracy: 0.8130\n",
            "Epoch 78/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.5404 - accuracy: 0.7454 - val_loss: 0.4872 - val_accuracy: 0.7805\n",
            "Epoch 79/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.5252 - accuracy: 0.7475 - val_loss: 0.4821 - val_accuracy: 0.7805\n",
            "Epoch 80/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.5269 - accuracy: 0.7515 - val_loss: 0.4718 - val_accuracy: 0.7886\n",
            "Epoch 81/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.5236 - accuracy: 0.7515 - val_loss: 0.4648 - val_accuracy: 0.7886\n",
            "Epoch 82/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.5435 - accuracy: 0.7536 - val_loss: 0.4727 - val_accuracy: 0.7967\n",
            "Epoch 83/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.5477 - accuracy: 0.7454 - val_loss: 0.4780 - val_accuracy: 0.7805\n",
            "Epoch 84/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.5385 - accuracy: 0.7393 - val_loss: 0.4916 - val_accuracy: 0.7724\n",
            "Epoch 85/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.5330 - accuracy: 0.7597 - val_loss: 0.4706 - val_accuracy: 0.8049\n",
            "Epoch 86/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.5312 - accuracy: 0.7597 - val_loss: 0.4645 - val_accuracy: 0.7886\n",
            "Epoch 87/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.5299 - accuracy: 0.7454 - val_loss: 0.4612 - val_accuracy: 0.7967\n",
            "Epoch 88/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.5425 - accuracy: 0.7576 - val_loss: 0.5303 - val_accuracy: 0.7480\n",
            "Epoch 89/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.5518 - accuracy: 0.7393 - val_loss: 0.4625 - val_accuracy: 0.8049\n",
            "Epoch 90/100\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.5282 - accuracy: 0.7434 - val_loss: 0.4820 - val_accuracy: 0.7805\n",
            "Epoch 91/100\n",
            "62/62 [==============================] - 0s 8ms/step - loss: 0.5217 - accuracy: 0.7617 - val_loss: 0.4468 - val_accuracy: 0.8130\n",
            "Epoch 92/100\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.5267 - accuracy: 0.7658 - val_loss: 0.4556 - val_accuracy: 0.8049\n",
            "Epoch 93/100\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.5281 - accuracy: 0.7658 - val_loss: 0.4905 - val_accuracy: 0.7805\n",
            "Epoch 94/100\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.5307 - accuracy: 0.7536 - val_loss: 0.4482 - val_accuracy: 0.8130\n",
            "Epoch 95/100\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.5220 - accuracy: 0.7800 - val_loss: 0.4724 - val_accuracy: 0.7886\n",
            "Epoch 96/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.5334 - accuracy: 0.7576 - val_loss: 0.4571 - val_accuracy: 0.7967\n",
            "Epoch 97/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.5307 - accuracy: 0.7475 - val_loss: 0.4661 - val_accuracy: 0.7967\n",
            "Epoch 98/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.5389 - accuracy: 0.7251 - val_loss: 0.5560 - val_accuracy: 0.7073\n",
            "Epoch 99/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.5271 - accuracy: 0.7556 - val_loss: 0.4566 - val_accuracy: 0.8049\n",
            "Epoch 100/100\n",
            "62/62 [==============================] - 0s 5ms/step - loss: 0.5198 - accuracy: 0.7719 - val_loss: 0.4630 - val_accuracy: 0.7805\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f0089fabd60>"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_model.save(\"best_model_super.h5\")"
      ],
      "metadata": {
        "id": "VLlQM-4TqyIw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "modelOriginal = load_model(\"model.h5\")\n",
        "modelHp = load_model(\"best_model_hp.h5\")\n",
        "modelRe = load_model(\"best_model_regularization.h5\")\n",
        "modelOp = load_model(\"best_model_optimization.h5\")\n",
        "modelSuper = load_model(\"best_model_super.h5\")\n",
        "\n",
        "lossOriginal, accuracyOriginal = modelOriginal.evaluate(X_test, y_test)\n",
        "lossHp, accuracyHp = modelHp.evaluate(X_test, y_test)\n",
        "lossRe, accuracyRe = modelRe.evaluate(X_test, y_test)\n",
        "lossOp, accuracyOp = modelOp.evaluate(X_test, y_test)\n",
        "lossSuper, accuracySuper = modelSuper.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9deVfOnns3fT",
        "outputId": "f49682eb-f911-47a2-bc0a-f2c1fb6694d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
            "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6000 - accuracy: 0.7078\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5180 - accuracy: 0.7403\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6274 - accuracy: 0.7013\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6346 - accuracy: 0.7208\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5382 - accuracy: 0.7208\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create the DataFrame\n",
        "df = pd.DataFrame({'Model': ['Original','Hyperparameter Tuning (Keras Tuner)','Regularization (L2 Regularization)','Optimization (Adam -> RMSprop)','Combined 3 ways'],\n",
        "                   'Loss': [lossOriginal, lossHp, lossRe, lossOp, lossSuper],\n",
        "                   'Accuracy': [accuracyOriginal, accuracyHp, accuracyRe, accuracyOp, accuracySuper]})\n",
        "\n",
        "# print the table using tabulate\n",
        "print(tabulate(df, headers='keys', tablefmt='pipe', floatfmt='.4f'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6t453wmXwTf0",
        "outputId": "92de189e-1266-40ab-d3e2-e3377795d4dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "|    | Model                               |   Loss |   Accuracy |\n",
            "|---:|:------------------------------------|-------:|-----------:|\n",
            "|  0 | Original                            | 0.6000 |     0.7078 |\n",
            "|  1 | Hyperparameter Tuning (Keras Tuner) | 0.5180 |     0.7403 |\n",
            "|  2 | Regularization (L2 Regularization)  | 0.6274 |     0.7013 |\n",
            "|  3 | Optimization (Adam -> RMSprop)      | 0.6346 |     0.7208 |\n",
            "|  4 | Combined 3 ways                     | 0.5382 |     0.7208 |\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Combining all three techniques has resulted in a better performing model with improved accuracy."
      ],
      "metadata": {
        "id": "ED7ZtxIcuGCN"
      }
    }
  ]
}